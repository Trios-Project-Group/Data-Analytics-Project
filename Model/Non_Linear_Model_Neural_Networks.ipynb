{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Import all packages</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Operations with dataframe </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>is_paid</th>\n",
       "      <th>num_subscribers</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>rating</th>\n",
       "      <th>num_reviews</th>\n",
       "      <th>num_published_lectures</th>\n",
       "      <th>num_published_practice_tests</th>\n",
       "      <th>created</th>\n",
       "      <th>published_time</th>\n",
       "      <th>discount_price__amount</th>\n",
       "      <th>price_detail__amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>567828</td>\n",
       "      <td>2020 Complete Python Bootcamp: From Zero to He...</td>\n",
       "      <td>/course/complete-python-bootcamp/</td>\n",
       "      <td>True</td>\n",
       "      <td>1086954</td>\n",
       "      <td>4.56326</td>\n",
       "      <td>4.56743</td>\n",
       "      <td>314098</td>\n",
       "      <td>152</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-07-29T00:12:23Z</td>\n",
       "      <td>2015-10-12T21:42:53Z</td>\n",
       "      <td>455.0</td>\n",
       "      <td>8640.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>625204</td>\n",
       "      <td>The Web Developer Bootcamp</td>\n",
       "      <td>/course/the-web-developer-bootcamp/</td>\n",
       "      <td>True</td>\n",
       "      <td>592474</td>\n",
       "      <td>4.64777</td>\n",
       "      <td>4.65291</td>\n",
       "      <td>181621</td>\n",
       "      <td>405</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-09-28T21:32:19Z</td>\n",
       "      <td>2015-11-02T21:13:27Z</td>\n",
       "      <td>455.0</td>\n",
       "      <td>8640.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>950390</td>\n",
       "      <td>Machine Learning A-Z™: Hands-On Python &amp; R In ...</td>\n",
       "      <td>/course/machinelearning/</td>\n",
       "      <td>True</td>\n",
       "      <td>687330</td>\n",
       "      <td>4.55210</td>\n",
       "      <td>4.54932</td>\n",
       "      <td>131007</td>\n",
       "      <td>323</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-09-05T09:54:22Z</td>\n",
       "      <td>2016-09-13T21:43:44Z</td>\n",
       "      <td>455.0</td>\n",
       "      <td>8640.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>756150</td>\n",
       "      <td>Angular - The Complete Guide (2020 Edition)</td>\n",
       "      <td>/course/the-complete-guide-to-angular-2/</td>\n",
       "      <td>True</td>\n",
       "      <td>417746</td>\n",
       "      <td>4.57687</td>\n",
       "      <td>4.58594</td>\n",
       "      <td>128705</td>\n",
       "      <td>455</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-02-08T17:02:55Z</td>\n",
       "      <td>2016-02-11T07:29:29Z</td>\n",
       "      <td>462.0</td>\n",
       "      <td>8640.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>533682</td>\n",
       "      <td>Java Programming Masterclass for Software Deve...</td>\n",
       "      <td>/course/java-the-complete-java-developer-course/</td>\n",
       "      <td>True</td>\n",
       "      <td>497195</td>\n",
       "      <td>4.56571</td>\n",
       "      <td>4.57203</td>\n",
       "      <td>122306</td>\n",
       "      <td>400</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-06-21T20:25:56Z</td>\n",
       "      <td>2015-07-21T22:01:13Z</td>\n",
       "      <td>455.0</td>\n",
       "      <td>8640.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32746</th>\n",
       "      <td>1516977</td>\n",
       "      <td>Fundamental Service Oriented Arch (SOA) Securi...</td>\n",
       "      <td>/course/fundamental-service-oriented-arch-soa-...</td>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "      <td>3.25000</td>\n",
       "      <td>2.65702</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2018-01-19T09:03:46Z</td>\n",
       "      <td>2018-01-28T09:20:37Z</td>\n",
       "      <td>455.0</td>\n",
       "      <td>1280.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32747</th>\n",
       "      <td>1479824</td>\n",
       "      <td>Linux Certification for Experts - Practice Tes...</td>\n",
       "      <td>/course/linux-certification-for-beginners-prac...</td>\n",
       "      <td>True</td>\n",
       "      <td>15</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>3.56818</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-12-23T12:44:39Z</td>\n",
       "      <td>2017-12-24T07:38:36Z</td>\n",
       "      <td>455.0</td>\n",
       "      <td>1280.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32748</th>\n",
       "      <td>1879598</td>\n",
       "      <td>SAP SuccessFactors Employee Central Payroll Fu...</td>\n",
       "      <td>/course/public-transport-management-systems/</td>\n",
       "      <td>True</td>\n",
       "      <td>19</td>\n",
       "      <td>2.75000</td>\n",
       "      <td>2.70354</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-08-27T14:43:42Z</td>\n",
       "      <td>2018-09-19T23:19:18Z</td>\n",
       "      <td>1280.0</td>\n",
       "      <td>1280.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32749</th>\n",
       "      <td>1940616</td>\n",
       "      <td>Comptia Linux+ / LPIC-1 (102-400)</td>\n",
       "      <td>/course/comptia-linux-lpic-1-102-400/</td>\n",
       "      <td>True</td>\n",
       "      <td>1082</td>\n",
       "      <td>3.75000</td>\n",
       "      <td>3.72059</td>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-09-30T15:11:27Z</td>\n",
       "      <td>2018-12-11T16:22:32Z</td>\n",
       "      <td>455.0</td>\n",
       "      <td>1280.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32750</th>\n",
       "      <td>543712</td>\n",
       "      <td>Cisco Networking CCNA IPv6 OSPF</td>\n",
       "      <td>/course/networkingstepbystep-ipv6-ospf/</td>\n",
       "      <td>True</td>\n",
       "      <td>858</td>\n",
       "      <td>4.50000</td>\n",
       "      <td>4.48220</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-07-03T02:24:30Z</td>\n",
       "      <td>2015-07-07T00:01:23Z</td>\n",
       "      <td>455.0</td>\n",
       "      <td>8640.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32751 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                              title  \\\n",
       "0       567828  2020 Complete Python Bootcamp: From Zero to He...   \n",
       "1       625204                         The Web Developer Bootcamp   \n",
       "2       950390  Machine Learning A-Z™: Hands-On Python & R In ...   \n",
       "3       756150        Angular - The Complete Guide (2020 Edition)   \n",
       "4       533682  Java Programming Masterclass for Software Deve...   \n",
       "...        ...                                                ...   \n",
       "32746  1516977  Fundamental Service Oriented Arch (SOA) Securi...   \n",
       "32747  1479824  Linux Certification for Experts - Practice Tes...   \n",
       "32748  1879598  SAP SuccessFactors Employee Central Payroll Fu...   \n",
       "32749  1940616                  Comptia Linux+ / LPIC-1 (102-400)   \n",
       "32750   543712                    Cisco Networking CCNA IPv6 OSPF   \n",
       "\n",
       "                                                     url  is_paid  \\\n",
       "0                      /course/complete-python-bootcamp/     True   \n",
       "1                    /course/the-web-developer-bootcamp/     True   \n",
       "2                               /course/machinelearning/     True   \n",
       "3               /course/the-complete-guide-to-angular-2/     True   \n",
       "4       /course/java-the-complete-java-developer-course/     True   \n",
       "...                                                  ...      ...   \n",
       "32746  /course/fundamental-service-oriented-arch-soa-...     True   \n",
       "32747  /course/linux-certification-for-beginners-prac...     True   \n",
       "32748       /course/public-transport-management-systems/     True   \n",
       "32749              /course/comptia-linux-lpic-1-102-400/     True   \n",
       "32750            /course/networkingstepbystep-ipv6-ospf/     True   \n",
       "\n",
       "       num_subscribers  avg_rating   rating  num_reviews  \\\n",
       "0              1086954     4.56326  4.56743       314098   \n",
       "1               592474     4.64777  4.65291       181621   \n",
       "2               687330     4.55210  4.54932       131007   \n",
       "3               417746     4.57687  4.58594       128705   \n",
       "4               497195     4.56571  4.57203       122306   \n",
       "...                ...         ...      ...          ...   \n",
       "32746               16     3.25000  2.65702            2   \n",
       "32747               15     4.00000  3.56818            2   \n",
       "32748               19     2.75000  2.70354            2   \n",
       "32749             1082     3.75000  3.72059            2   \n",
       "32750              858     4.50000  4.48220            2   \n",
       "\n",
       "       num_published_lectures  num_published_practice_tests  \\\n",
       "0                         152                             0   \n",
       "1                         405                             0   \n",
       "2                         323                             0   \n",
       "3                         455                             0   \n",
       "4                         400                             0   \n",
       "...                       ...                           ...   \n",
       "32746                       0                             2   \n",
       "32747                       0                             2   \n",
       "32748                       5                             0   \n",
       "32749                      31                             0   \n",
       "32750                      24                             0   \n",
       "\n",
       "                    created        published_time  discount_price__amount  \\\n",
       "0      2015-07-29T00:12:23Z  2015-10-12T21:42:53Z                   455.0   \n",
       "1      2015-09-28T21:32:19Z  2015-11-02T21:13:27Z                   455.0   \n",
       "2      2016-09-05T09:54:22Z  2016-09-13T21:43:44Z                   455.0   \n",
       "3      2016-02-08T17:02:55Z  2016-02-11T07:29:29Z                   462.0   \n",
       "4      2015-06-21T20:25:56Z  2015-07-21T22:01:13Z                   455.0   \n",
       "...                     ...                   ...                     ...   \n",
       "32746  2018-01-19T09:03:46Z  2018-01-28T09:20:37Z                   455.0   \n",
       "32747  2017-12-23T12:44:39Z  2017-12-24T07:38:36Z                   455.0   \n",
       "32748  2018-08-27T14:43:42Z  2018-09-19T23:19:18Z                  1280.0   \n",
       "32749  2018-09-30T15:11:27Z  2018-12-11T16:22:32Z                   455.0   \n",
       "32750  2015-07-03T02:24:30Z  2015-07-07T00:01:23Z                   455.0   \n",
       "\n",
       "       price_detail__amount  \n",
       "0                    8640.0  \n",
       "1                    8640.0  \n",
       "2                    8640.0  \n",
       "3                    8640.0  \n",
       "4                    8640.0  \n",
       "...                     ...  \n",
       "32746                1280.0  \n",
       "32747                1280.0  \n",
       "32748                1280.0  \n",
       "32749                1280.0  \n",
       "32750                8640.0  \n",
       "\n",
       "[32751 rows x 14 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Development_IT.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check for null values\n",
    "df.isnull().values.any() #False - implies no NULL values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "#Check for duplicates if any\n",
    "l=[]\n",
    "for i,j in enumerate(df['id'].value_counts()):\n",
    "    if j==2:\n",
    "        l.append(df['id'].value_counts().index[i])\n",
    "print(l)#Implies duplicates are removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'title', 'url', 'is_paid', 'num_subscribers', 'avg_rating',\n",
      "       'rating', 'num_reviews', 'num_published_lectures',\n",
      "       'num_published_practice_tests', 'created', 'published_time',\n",
      "       'discount_price__amount', 'price_detail__amount'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#We need to apply a neural network which is a non linear model.\n",
    "#We have many steps to do the following thing.\n",
    "#Firstly identiy all columns used for identifying target variable.\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select few columns(features) for Neural network - num_subscribers, avg_rating, rating, num_reviews, num_published_lectures, num_published_practice tests, discount_price__amount.\n",
    "#Target feature would be price_detail__amount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Import all packages </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Consider the required sample for training and testing Neural Network </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>is_paid</th>\n",
       "      <th>num_subscribers</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>rating</th>\n",
       "      <th>num_reviews</th>\n",
       "      <th>num_published_lectures</th>\n",
       "      <th>num_published_practice_tests</th>\n",
       "      <th>created</th>\n",
       "      <th>published_time</th>\n",
       "      <th>discount_price__amount</th>\n",
       "      <th>price_detail__amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26688</th>\n",
       "      <td>2311894</td>\n",
       "      <td>SCCM Administration - Be an 'Expert'!</td>\n",
       "      <td>/course/sccm-administration-expert/</td>\n",
       "      <td>True</td>\n",
       "      <td>438</td>\n",
       "      <td>4.36364</td>\n",
       "      <td>4.35555</td>\n",
       "      <td>66</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-04-08T06:06:14Z</td>\n",
       "      <td>2019-04-18T12:18:26Z</td>\n",
       "      <td>455.0</td>\n",
       "      <td>4800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26988</th>\n",
       "      <td>63060</td>\n",
       "      <td>Become TOGAF Certified with exam preparation f...</td>\n",
       "      <td>/course/togaf-exam-preparation-level-2/</td>\n",
       "      <td>True</td>\n",
       "      <td>928</td>\n",
       "      <td>3.95000</td>\n",
       "      <td>4.00476</td>\n",
       "      <td>56</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-06-30T13:31:25Z</td>\n",
       "      <td>2013-07-07T21:58:54Z</td>\n",
       "      <td>1280.0</td>\n",
       "      <td>1280.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30063</th>\n",
       "      <td>2565064</td>\n",
       "      <td>Java SE11 Programmer 1 (1Z0-815) - Practice Tests</td>\n",
       "      <td>/course/java-se11-programmer-1-1z0-815-practic...</td>\n",
       "      <td>True</td>\n",
       "      <td>168</td>\n",
       "      <td>4.20000</td>\n",
       "      <td>4.20121</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2019-09-18T04:49:09Z</td>\n",
       "      <td>2019-09-24T09:03:06Z</td>\n",
       "      <td>455.0</td>\n",
       "      <td>1600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7345</th>\n",
       "      <td>1661674</td>\n",
       "      <td>C# basics in 70 minutes for beginners: Learn C...</td>\n",
       "      <td>/course/learn-c-sharp-fundamentals/</td>\n",
       "      <td>True</td>\n",
       "      <td>4642</td>\n",
       "      <td>3.65000</td>\n",
       "      <td>3.11321</td>\n",
       "      <td>23</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-04-24T20:32:02Z</td>\n",
       "      <td>2018-04-29T21:31:43Z</td>\n",
       "      <td>455.0</td>\n",
       "      <td>2240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1295</th>\n",
       "      <td>14346</td>\n",
       "      <td>Learn C# Programming (In Ten Easy Steps)</td>\n",
       "      <td>/course/learn-c-sharp-programming-in-ten-easy-...</td>\n",
       "      <td>True</td>\n",
       "      <td>3994</td>\n",
       "      <td>4.32292</td>\n",
       "      <td>4.27152</td>\n",
       "      <td>528</td>\n",
       "      <td>126</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-02-22T18:11:03Z</td>\n",
       "      <td>2012-03-26T15:30:40Z</td>\n",
       "      <td>481.0</td>\n",
       "      <td>8960.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15432</th>\n",
       "      <td>1074796</td>\n",
       "      <td>Learn Business Negotiation Skills</td>\n",
       "      <td>/course/learn-business-negotiation-skills/</td>\n",
       "      <td>True</td>\n",
       "      <td>974</td>\n",
       "      <td>4.50000</td>\n",
       "      <td>4.38601</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-13T13:36:01Z</td>\n",
       "      <td>2017-01-16T23:37:13Z</td>\n",
       "      <td>455.0</td>\n",
       "      <td>1600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27659</th>\n",
       "      <td>1128926</td>\n",
       "      <td>Wordpress Security Master Class Protect Your B...</td>\n",
       "      <td>/course/wordpress-security-master-class-protec...</td>\n",
       "      <td>True</td>\n",
       "      <td>5096</td>\n",
       "      <td>4.60000</td>\n",
       "      <td>4.32932</td>\n",
       "      <td>39</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-02-27T14:55:27Z</td>\n",
       "      <td>2017-03-24T19:13:26Z</td>\n",
       "      <td>455.0</td>\n",
       "      <td>8640.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15997</th>\n",
       "      <td>994242</td>\n",
       "      <td>Jesus Teaches YOU How to Build a WorldClass Bu...</td>\n",
       "      <td>/course/the-jesus-secret-how-to-build-a-world-...</td>\n",
       "      <td>True</td>\n",
       "      <td>981</td>\n",
       "      <td>4.90000</td>\n",
       "      <td>4.89161</td>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-10-25T17:25:56Z</td>\n",
       "      <td>2016-10-26T15:03:03Z</td>\n",
       "      <td>455.0</td>\n",
       "      <td>1280.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14682</th>\n",
       "      <td>1606940</td>\n",
       "      <td>Sourcing From China | Crowdfunding Case Study</td>\n",
       "      <td>/course/sourcing-from-china-crowdfunding-case-...</td>\n",
       "      <td>True</td>\n",
       "      <td>3669</td>\n",
       "      <td>3.90000</td>\n",
       "      <td>3.75780</td>\n",
       "      <td>32</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-03-20T07:00:33Z</td>\n",
       "      <td>2018-03-28T21:15:30Z</td>\n",
       "      <td>455.0</td>\n",
       "      <td>1280.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4486</th>\n",
       "      <td>834924</td>\n",
       "      <td>How to create HTML Forms</td>\n",
       "      <td>/course/how-to-create-html-forms/</td>\n",
       "      <td>True</td>\n",
       "      <td>3816</td>\n",
       "      <td>3.75000</td>\n",
       "      <td>3.65281</td>\n",
       "      <td>74</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-04-29T00:54:50Z</td>\n",
       "      <td>2016-04-29T04:48:25Z</td>\n",
       "      <td>455.0</td>\n",
       "      <td>1920.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4913 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                              title  \\\n",
       "26688  2311894              SCCM Administration - Be an 'Expert'!   \n",
       "26988    63060  Become TOGAF Certified with exam preparation f...   \n",
       "30063  2565064  Java SE11 Programmer 1 (1Z0-815) - Practice Tests   \n",
       "7345   1661674  C# basics in 70 minutes for beginners: Learn C...   \n",
       "1295     14346           Learn C# Programming (In Ten Easy Steps)   \n",
       "...        ...                                                ...   \n",
       "15432  1074796                  Learn Business Negotiation Skills   \n",
       "27659  1128926  Wordpress Security Master Class Protect Your B...   \n",
       "15997   994242  Jesus Teaches YOU How to Build a WorldClass Bu...   \n",
       "14682  1606940      Sourcing From China | Crowdfunding Case Study   \n",
       "4486    834924                           How to create HTML Forms   \n",
       "\n",
       "                                                     url  is_paid  \\\n",
       "26688                /course/sccm-administration-expert/     True   \n",
       "26988            /course/togaf-exam-preparation-level-2/     True   \n",
       "30063  /course/java-se11-programmer-1-1z0-815-practic...     True   \n",
       "7345                 /course/learn-c-sharp-fundamentals/     True   \n",
       "1295   /course/learn-c-sharp-programming-in-ten-easy-...     True   \n",
       "...                                                  ...      ...   \n",
       "15432         /course/learn-business-negotiation-skills/     True   \n",
       "27659  /course/wordpress-security-master-class-protec...     True   \n",
       "15997  /course/the-jesus-secret-how-to-build-a-world-...     True   \n",
       "14682  /course/sourcing-from-china-crowdfunding-case-...     True   \n",
       "4486                   /course/how-to-create-html-forms/     True   \n",
       "\n",
       "       num_subscribers  avg_rating   rating  num_reviews  \\\n",
       "26688              438     4.36364  4.35555           66   \n",
       "26988              928     3.95000  4.00476           56   \n",
       "30063              168     4.20000  4.20121           12   \n",
       "7345              4642     3.65000  3.11321           23   \n",
       "1295              3994     4.32292  4.27152          528   \n",
       "...                ...         ...      ...          ...   \n",
       "15432              974     4.50000  4.38601           23   \n",
       "27659             5096     4.60000  4.32932           39   \n",
       "15997              981     4.90000  4.89161           18   \n",
       "14682             3669     3.90000  3.75780           32   \n",
       "4486              3816     3.75000  3.65281           74   \n",
       "\n",
       "       num_published_lectures  num_published_practice_tests  \\\n",
       "26688                      55                             0   \n",
       "26988                      19                             0   \n",
       "30063                       0                             5   \n",
       "7345                       19                             0   \n",
       "1295                      126                             0   \n",
       "...                       ...                           ...   \n",
       "15432                       7                             0   \n",
       "27659                      42                             0   \n",
       "15997                       7                             0   \n",
       "14682                      12                             0   \n",
       "4486                        8                             0   \n",
       "\n",
       "                    created        published_time  discount_price__amount  \\\n",
       "26688  2019-04-08T06:06:14Z  2019-04-18T12:18:26Z                   455.0   \n",
       "26988  2013-06-30T13:31:25Z  2013-07-07T21:58:54Z                  1280.0   \n",
       "30063  2019-09-18T04:49:09Z  2019-09-24T09:03:06Z                   455.0   \n",
       "7345   2018-04-24T20:32:02Z  2018-04-29T21:31:43Z                   455.0   \n",
       "1295   2012-02-22T18:11:03Z  2012-03-26T15:30:40Z                   481.0   \n",
       "...                     ...                   ...                     ...   \n",
       "15432  2017-01-13T13:36:01Z  2017-01-16T23:37:13Z                   455.0   \n",
       "27659  2017-02-27T14:55:27Z  2017-03-24T19:13:26Z                   455.0   \n",
       "15997  2016-10-25T17:25:56Z  2016-10-26T15:03:03Z                   455.0   \n",
       "14682  2018-03-20T07:00:33Z  2018-03-28T21:15:30Z                   455.0   \n",
       "4486   2016-04-29T00:54:50Z  2016-04-29T04:48:25Z                   455.0   \n",
       "\n",
       "       price_detail__amount  \n",
       "26688                4800.0  \n",
       "26988                1280.0  \n",
       "30063                1600.0  \n",
       "7345                 2240.0  \n",
       "1295                 8960.0  \n",
       "...                     ...  \n",
       "15432                1600.0  \n",
       "27659                8640.0  \n",
       "15997                1280.0  \n",
       "14682                1280.0  \n",
       "4486                 1920.0  \n",
       "\n",
       "[4913 rows x 14 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample = df.sample(frac=0.15, axis=0)\n",
    "df_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Consider required columns for input feature and target variable\n",
    "X = df_sample[['num_subscribers', 'num_reviews', 'num_published_lectures']].values\n",
    "Y = df_sample[['avg_rating']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From e:\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From e:\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From e:\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From e:\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From e:\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From e:\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Epoch 1/35\n",
      "4421/4421 [==============================] - 1s 283us/step - loss: 249518.9341 - mean_absolute_error: 66.6962\n",
      "Epoch 2/35\n",
      "4421/4421 [==============================] - 0s 57us/step - loss: 80961.7664 - mean_absolute_error: 58.7053\n",
      "Epoch 3/35\n",
      "4421/4421 [==============================] - 0s 61us/step - loss: 41677.6038 - mean_absolute_error: 45.7273\n",
      "Epoch 4/35\n",
      "4421/4421 [==============================] - 0s 54us/step - loss: 114375.2310 - mean_absolute_error: 34.5554\n",
      "Epoch 5/35\n",
      "4421/4421 [==============================] - 0s 51us/step - loss: 204840.0481 - mean_absolute_error: 33.8708\n",
      "Epoch 6/35\n",
      "4421/4421 [==============================] - 0s 54us/step - loss: 19467.0155 - mean_absolute_error: 28.3489\n",
      "Epoch 7/35\n",
      "4421/4421 [==============================] - 0s 60us/step - loss: 13370.3075 - mean_absolute_error: 26.6632\n",
      "Epoch 8/35\n",
      "4421/4421 [==============================] - 0s 50us/step - loss: 8357.0384 - mean_absolute_error: 18.5755\n",
      "Epoch 9/35\n",
      "4421/4421 [==============================] - 0s 52us/step - loss: 9894.6246 - mean_absolute_error: 15.6752\n",
      "Epoch 10/35\n",
      "4421/4421 [==============================] - 0s 67us/step - loss: 9267.1496 - mean_absolute_error: 15.1308\n",
      "Epoch 11/35\n",
      "4421/4421 [==============================] - 0s 53us/step - loss: 4122.8958 - mean_absolute_error: 11.3704\n",
      "Epoch 12/35\n",
      "4421/4421 [==============================] - 0s 53us/step - loss: 6397.8768 - mean_absolute_error: 13.2645\n",
      "Epoch 13/35\n",
      "4421/4421 [==============================] - 0s 55us/step - loss: 2557.7265 - mean_absolute_error: 12.4067\n",
      "Epoch 14/35\n",
      "4421/4421 [==============================] - 0s 53us/step - loss: 3759.6868 - mean_absolute_error: 11.0478\n",
      "Epoch 15/35\n",
      "4421/4421 [==============================] - 0s 51us/step - loss: 2182.4496 - mean_absolute_error: 10.0168\n",
      "Epoch 16/35\n",
      "4421/4421 [==============================] - 0s 48us/step - loss: 6097.6725 - mean_absolute_error: 12.0762\n",
      "Epoch 17/35\n",
      "4421/4421 [==============================] - 0s 48us/step - loss: 3327.1715 - mean_absolute_error: 13.4717\n",
      "Epoch 18/35\n",
      "4421/4421 [==============================] - 0s 48us/step - loss: 2121.5949 - mean_absolute_error: 10.2967\n",
      "Epoch 19/35\n",
      "4421/4421 [==============================] - 0s 49us/step - loss: 3210.0224 - mean_absolute_error: 8.7759\n",
      "Epoch 20/35\n",
      "4421/4421 [==============================] - 0s 48us/step - loss: 1403.6109 - mean_absolute_error: 7.5230\n",
      "Epoch 21/35\n",
      "4421/4421 [==============================] - 0s 50us/step - loss: 1197.7481 - mean_absolute_error: 6.8942\n",
      "Epoch 22/35\n",
      "4421/4421 [==============================] - 0s 50us/step - loss: 5550.9773 - mean_absolute_error: 9.5461\n",
      "Epoch 23/35\n",
      "4421/4421 [==============================] - 0s 49us/step - loss: 5499.6684 - mean_absolute_error: 14.6427\n",
      "Epoch 24/35\n",
      "4421/4421 [==============================] - 0s 48us/step - loss: 6572.6554 - mean_absolute_error: 11.8944\n",
      "Epoch 25/35\n",
      "4421/4421 [==============================] - 0s 52us/step - loss: 1344.1638 - mean_absolute_error: 8.1576\n",
      "Epoch 26/35\n",
      "4421/4421 [==============================] - 0s 56us/step - loss: 641.0942 - mean_absolute_error: 5.6770\n",
      "Epoch 27/35\n",
      "4421/4421 [==============================] - 0s 55us/step - loss: 525.9203 - mean_absolute_error: 4.8466\n",
      "Epoch 28/35\n",
      "4421/4421 [==============================] - 0s 53us/step - loss: 989.7596 - mean_absolute_error: 4.9356\n",
      "Epoch 29/35\n",
      "4421/4421 [==============================] - 0s 63us/step - loss: 346.2815 - mean_absolute_error: 4.3852\n",
      "Epoch 30/35\n",
      "4421/4421 [==============================] - 0s 58us/step - loss: 64.8601 - mean_absolute_error: 2.9909 0s - loss: 76.9532 - mean_absolute_error: 3.\n",
      "Epoch 31/35\n",
      "4421/4421 [==============================] - 0s 57us/step - loss: 66.2752 - mean_absolute_error: 2.6933\n",
      "Epoch 32/35\n",
      "4421/4421 [==============================] - 0s 62us/step - loss: 141.8991 - mean_absolute_error: 3.0418\n",
      "Epoch 33/35\n",
      "4421/4421 [==============================] - 0s 54us/step - loss: 592.0529 - mean_absolute_error: 4.1524\n",
      "Epoch 34/35\n",
      "4421/4421 [==============================] - 0s 55us/step - loss: 402.0690 - mean_absolute_error: 4.6506\n",
      "Epoch 35/35\n",
      "4421/4421 [==============================] - 0s 54us/step - loss: 162.6286 - mean_absolute_error: 3.3047\n",
      "Epoch 1/35\n",
      "4421/4421 [==============================] - 1s 138us/step - loss: 185509.2158 - mean_absolute_error: 76.1722\n",
      "Epoch 2/35\n",
      "4421/4421 [==============================] - 0s 50us/step - loss: 106672.1417 - mean_absolute_error: 70.2285\n",
      "Epoch 3/35\n",
      "4421/4421 [==============================] - 0s 51us/step - loss: 116417.5612 - mean_absolute_error: 52.0720\n",
      "Epoch 4/35\n",
      "4421/4421 [==============================] - 0s 53us/step - loss: 29002.3311 - mean_absolute_error: 38.3988\n",
      "Epoch 5/35\n",
      "4421/4421 [==============================] - 0s 53us/step - loss: 39642.0921 - mean_absolute_error: 37.9960\n",
      "Epoch 6/35\n",
      "4421/4421 [==============================] - 0s 52us/step - loss: 35608.7557 - mean_absolute_error: 29.5728\n",
      "Epoch 7/35\n",
      "4421/4421 [==============================] - 0s 51us/step - loss: 37456.9811 - mean_absolute_error: 24.9418\n",
      "Epoch 8/35\n",
      "4421/4421 [==============================] - 0s 52us/step - loss: 11721.7918 - mean_absolute_error: 24.6279\n",
      "Epoch 9/35\n",
      "4421/4421 [==============================] - 0s 53us/step - loss: 16006.7093 - mean_absolute_error: 19.5491\n",
      "Epoch 10/35\n",
      "4421/4421 [==============================] - 0s 50us/step - loss: 6598.2782 - mean_absolute_error: 14.9289\n",
      "Epoch 11/35\n",
      "4421/4421 [==============================] - 0s 48us/step - loss: 16047.8253 - mean_absolute_error: 19.6706\n",
      "Epoch 12/35\n",
      "4421/4421 [==============================] - 0s 54us/step - loss: 9472.4816 - mean_absolute_error: 20.4134\n",
      "Epoch 13/35\n",
      "4421/4421 [==============================] - 0s 67us/step - loss: 18912.3101 - mean_absolute_error: 23.9501\n",
      "Epoch 14/35\n",
      "4421/4421 [==============================] - 0s 55us/step - loss: 6130.5757 - mean_absolute_error: 16.8813\n",
      "Epoch 15/35\n",
      "4421/4421 [==============================] - 0s 59us/step - loss: 4173.5684 - mean_absolute_error: 11.4662\n",
      "Epoch 16/35\n",
      "4421/4421 [==============================] - 0s 78us/step - loss: 5086.2322 - mean_absolute_error: 13.0791\n",
      "Epoch 17/35\n",
      "4421/4421 [==============================] - 0s 75us/step - loss: 3462.4947 - mean_absolute_error: 9.4469\n",
      "Epoch 18/35\n",
      "4421/4421 [==============================] - 0s 75us/step - loss: 4012.4036 - mean_absolute_error: 10.5678\n",
      "Epoch 19/35\n",
      "4421/4421 [==============================] - 0s 78us/step - loss: 2592.7234 - mean_absolute_error: 10.6591\n",
      "Epoch 20/35\n",
      "4421/4421 [==============================] - 0s 62us/step - loss: 14707.7160 - mean_absolute_error: 12.0325\n",
      "Epoch 21/35\n",
      "4421/4421 [==============================] - 0s 58us/step - loss: 6136.2066 - mean_absolute_error: 8.4875\n",
      "Epoch 22/35\n",
      "4421/4421 [==============================] - 0s 70us/step - loss: 10431.1340 - mean_absolute_error: 11.8645\n",
      "Epoch 23/35\n",
      "4421/4421 [==============================] - 0s 74us/step - loss: 4952.2733 - mean_absolute_error: 10.8107\n",
      "Epoch 24/35\n",
      "4421/4421 [==============================] - 0s 73us/step - loss: 4294.1614 - mean_absolute_error: 12.6254\n",
      "Epoch 25/35\n",
      "4421/4421 [==============================] - 0s 57us/step - loss: 5349.4397 - mean_absolute_error: 12.7963\n",
      "Epoch 26/35\n",
      "4421/4421 [==============================] - 0s 51us/step - loss: 4340.6802 - mean_absolute_error: 11.7738\n",
      "Epoch 27/35\n",
      "4421/4421 [==============================] - 0s 52us/step - loss: 2511.7004 - mean_absolute_error: 8.8029\n",
      "Epoch 28/35\n",
      "4421/4421 [==============================] - 0s 53us/step - loss: 993.4210 - mean_absolute_error: 7.5520\n",
      "Epoch 29/35\n",
      "4421/4421 [==============================] - 0s 60us/step - loss: 481.0845 - mean_absolute_error: 5.0202\n",
      "Epoch 30/35\n",
      "4421/4421 [==============================] - 0s 58us/step - loss: 849.6727 - mean_absolute_error: 4.4065\n",
      "Epoch 31/35\n",
      "4421/4421 [==============================] - 0s 51us/step - loss: 331.7796 - mean_absolute_error: 4.2915\n",
      "Epoch 32/35\n",
      "4421/4421 [==============================] - 0s 55us/step - loss: 678.8041 - mean_absolute_error: 4.9823\n",
      "Epoch 33/35\n",
      "4421/4421 [==============================] - 0s 57us/step - loss: 531.1153 - mean_absolute_error: 5.5717\n",
      "Epoch 34/35\n",
      "4421/4421 [==============================] - 0s 55us/step - loss: 275.7195 - mean_absolute_error: 4.0452\n",
      "Epoch 35/35\n",
      "4421/4421 [==============================] - 0s 58us/step - loss: 744.1812 - mean_absolute_error: 5.5814\n",
      "Epoch 1/35\n",
      "4421/4421 [==============================] - 1s 124us/step - loss: 110486.7713 - mean_absolute_error: 52.0626\n",
      "Epoch 2/35\n",
      "4421/4421 [==============================] - 0s 49us/step - loss: 64685.2772 - mean_absolute_error: 42.8896\n",
      "Epoch 3/35\n",
      "4421/4421 [==============================] - 0s 59us/step - loss: 46687.6830 - mean_absolute_error: 35.0182\n",
      "Epoch 4/35\n",
      "4421/4421 [==============================] - 0s 68us/step - loss: 79385.4282 - mean_absolute_error: 39.8032\n",
      "Epoch 5/35\n",
      "4421/4421 [==============================] - 0s 67us/step - loss: 126964.9639 - mean_absolute_error: 37.1353\n",
      "Epoch 6/35\n",
      "4421/4421 [==============================] - 0s 69us/step - loss: 18647.7706 - mean_absolute_error: 23.9079\n",
      "Epoch 7/35\n",
      "4421/4421 [==============================] - 0s 71us/step - loss: 32772.3765 - mean_absolute_error: 25.5778\n",
      "Epoch 8/35\n",
      "4421/4421 [==============================] - 0s 59us/step - loss: 10436.9975 - mean_absolute_error: 14.1356\n",
      "Epoch 9/35\n",
      "4421/4421 [==============================] - 0s 58us/step - loss: 33616.6297 - mean_absolute_error: 16.3264\n",
      "Epoch 10/35\n",
      "4421/4421 [==============================] - 0s 56us/step - loss: 14900.9397 - mean_absolute_error: 16.1129\n",
      "Epoch 11/35\n",
      "4421/4421 [==============================] - 0s 63us/step - loss: 38397.6742 - mean_absolute_error: 16.2585\n",
      "Epoch 12/35\n",
      "4421/4421 [==============================] - 0s 56us/step - loss: 7001.7982 - mean_absolute_error: 15.0947\n",
      "Epoch 13/35\n",
      "4421/4421 [==============================] - 0s 58us/step - loss: 3830.7883 - mean_absolute_error: 12.7584\n",
      "Epoch 14/35\n",
      "4421/4421 [==============================] - 0s 57us/step - loss: 4635.5082 - mean_absolute_error: 11.2583\n",
      "Epoch 15/35\n",
      "4421/4421 [==============================] - 0s 59us/step - loss: 3523.1672 - mean_absolute_error: 11.7444\n",
      "Epoch 16/35\n",
      "4421/4421 [==============================] - 0s 56us/step - loss: 6796.9310 - mean_absolute_error: 10.5584\n",
      "Epoch 17/35\n",
      "4421/4421 [==============================] - 0s 57us/step - loss: 3942.2543 - mean_absolute_error: 12.2487\n",
      "Epoch 18/35\n",
      "4421/4421 [==============================] - 0s 56us/step - loss: 2668.6084 - mean_absolute_error: 10.1236\n",
      "Epoch 19/35\n",
      "4421/4421 [==============================] - 0s 63us/step - loss: 1306.8105 - mean_absolute_error: 9.0352\n",
      "Epoch 20/35\n",
      "4421/4421 [==============================] - 0s 64us/step - loss: 567.5722 - mean_absolute_error: 5.2930: 0s - loss: 1204.0602 - mean_absolute_error: 7\n",
      "Epoch 21/35\n",
      "4421/4421 [==============================] - 0s 56us/step - loss: 826.4207 - mean_absolute_error: 8.0197\n",
      "Epoch 22/35\n",
      "4421/4421 [==============================] - 0s 51us/step - loss: 7715.3443 - mean_absolute_error: 8.1515\n",
      "Epoch 23/35\n",
      "4421/4421 [==============================] - 0s 50us/step - loss: 2390.4775 - mean_absolute_error: 9.6283\n",
      "Epoch 24/35\n",
      "4421/4421 [==============================] - 0s 50us/step - loss: 4192.6482 - mean_absolute_error: 6.7093\n",
      "Epoch 25/35\n",
      "4421/4421 [==============================] - 0s 50us/step - loss: 494.0687 - mean_absolute_error: 4.7369\n",
      "Epoch 26/35\n",
      "4421/4421 [==============================] - 0s 50us/step - loss: 354.0651 - mean_absolute_error: 4.0412\n",
      "Epoch 27/35\n",
      "4421/4421 [==============================] - 0s 51us/step - loss: 153.0161 - mean_absolute_error: 2.6810\n",
      "Epoch 28/35\n",
      "4421/4421 [==============================] - 0s 51us/step - loss: 14.0385 - mean_absolute_error: 1.2916\n",
      "Epoch 29/35\n",
      "4421/4421 [==============================] - 0s 50us/step - loss: 38.7516 - mean_absolute_error: 1.1725\n",
      "Epoch 30/35\n",
      "4421/4421 [==============================] - 0s 51us/step - loss: 2.3390 - mean_absolute_error: 0.6550\n",
      "Epoch 31/35\n",
      "4421/4421 [==============================] - 0s 56us/step - loss: 4.6555 - mean_absolute_error: 0.6559\n",
      "Epoch 32/35\n",
      "4421/4421 [==============================] - 0s 53us/step - loss: 0.8551 - mean_absolute_error: 0.4633\n",
      "Epoch 33/35\n",
      "4421/4421 [==============================] - 0s 67us/step - loss: 4.5030 - mean_absolute_error: 0.4922\n",
      "Epoch 34/35\n",
      "4421/4421 [==============================] - 0s 69us/step - loss: 0.7441 - mean_absolute_error: 0.4337\n",
      "Epoch 35/35\n",
      "4421/4421 [==============================] - 0s 68us/step - loss: 0.8187 - mean_absolute_error: 0.4513\n",
      "Epoch 1/35\n",
      "4422/4422 [==============================] - 1s 140us/step - loss: 50771.6063 - mean_absolute_error: 35.4626\n",
      "Epoch 2/35\n",
      "4422/4422 [==============================] - 0s 52us/step - loss: 29913.2568 - mean_absolute_error: 28.3590\n",
      "Epoch 3/35\n",
      "4422/4422 [==============================] - 0s 53us/step - loss: 42402.7722 - mean_absolute_error: 44.3199\n",
      "Epoch 4/35\n",
      "4422/4422 [==============================] - 0s 67us/step - loss: 28782.6152 - mean_absolute_error: 30.2823\n",
      "Epoch 5/35\n",
      "4422/4422 [==============================] - 0s 66us/step - loss: 16025.3441 - mean_absolute_error: 25.8917\n",
      "Epoch 6/35\n",
      "4422/4422 [==============================] - 0s 57us/step - loss: 19125.5047 - mean_absolute_error: 21.8093\n",
      "Epoch 7/35\n",
      "4422/4422 [==============================] - 0s 49us/step - loss: 13993.6167 - mean_absolute_error: 15.9673\n",
      "Epoch 8/35\n",
      "4422/4422 [==============================] - 0s 57us/step - loss: 2027.4392 - mean_absolute_error: 10.3276\n",
      "Epoch 9/35\n",
      "4422/4422 [==============================] - 0s 63us/step - loss: 2323.4065 - mean_absolute_error: 10.8518\n",
      "Epoch 10/35\n",
      "4422/4422 [==============================] - 0s 55us/step - loss: 3026.9330 - mean_absolute_error: 10.4812\n",
      "Epoch 11/35\n",
      "4422/4422 [==============================] - 0s 62us/step - loss: 1195.6022 - mean_absolute_error: 8.0048\n",
      "Epoch 12/35\n",
      "4422/4422 [==============================] - 0s 60us/step - loss: 847.7035 - mean_absolute_error: 6.7379\n",
      "Epoch 13/35\n",
      "4422/4422 [==============================] - 0s 67us/step - loss: 1142.1217 - mean_absolute_error: 6.5110\n",
      "Epoch 14/35\n",
      "4422/4422 [==============================] - 0s 56us/step - loss: 1908.3503 - mean_absolute_error: 6.3462\n",
      "Epoch 15/35\n",
      "4422/4422 [==============================] - 0s 53us/step - loss: 1457.9873 - mean_absolute_error: 6.7527\n",
      "Epoch 16/35\n",
      "4422/4422 [==============================] - 0s 60us/step - loss: 1202.0198 - mean_absolute_error: 8.2433\n",
      "Epoch 17/35\n",
      "4422/4422 [==============================] - 0s 51us/step - loss: 2874.6318 - mean_absolute_error: 12.2752\n",
      "Epoch 18/35\n",
      "4422/4422 [==============================] - 0s 51us/step - loss: 29558.6951 - mean_absolute_error: 20.4148\n",
      "Epoch 19/35\n",
      "4422/4422 [==============================] - 0s 53us/step - loss: 6456.8874 - mean_absolute_error: 12.0879\n",
      "Epoch 20/35\n",
      "4422/4422 [==============================] - 0s 54us/step - loss: 5691.9629 - mean_absolute_error: 12.9921\n",
      "Epoch 21/35\n",
      "4422/4422 [==============================] - 0s 54us/step - loss: 4964.3625 - mean_absolute_error: 9.3574\n",
      "Epoch 22/35\n",
      "4422/4422 [==============================] - 0s 51us/step - loss: 3125.3335 - mean_absolute_error: 10.1585\n",
      "Epoch 23/35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4422/4422 [==============================] - 0s 52us/step - loss: 4511.0626 - mean_absolute_error: 6.7135\n",
      "Epoch 24/35\n",
      "4422/4422 [==============================] - 0s 52us/step - loss: 1316.3223 - mean_absolute_error: 7.4480\n",
      "Epoch 25/35\n",
      "4422/4422 [==============================] - 0s 49us/step - loss: 1811.3972 - mean_absolute_error: 8.0937\n",
      "Epoch 26/35\n",
      "4422/4422 [==============================] - 0s 49us/step - loss: 699.3772 - mean_absolute_error: 5.9133\n",
      "Epoch 27/35\n",
      "4422/4422 [==============================] - 0s 49us/step - loss: 459.7636 - mean_absolute_error: 4.7103\n",
      "Epoch 28/35\n",
      "4422/4422 [==============================] - 0s 51us/step - loss: 154.9313 - mean_absolute_error: 3.0441\n",
      "Epoch 29/35\n",
      "4422/4422 [==============================] - 0s 48us/step - loss: 123.2187 - mean_absolute_error: 1.9950\n",
      "Epoch 30/35\n",
      "4422/4422 [==============================] - 0s 46us/step - loss: 2.8778 - mean_absolute_error: 0.7254\n",
      "Epoch 31/35\n",
      "4422/4422 [==============================] - 0s 47us/step - loss: 0.4375 - mean_absolute_error: 0.4618\n",
      "Epoch 32/35\n",
      "4422/4422 [==============================] - 0s 46us/step - loss: 0.3911 - mean_absolute_error: 0.4284\n",
      "Epoch 33/35\n",
      "4422/4422 [==============================] - 0s 61us/step - loss: 5.5070 - mean_absolute_error: 0.5301\n",
      "Epoch 34/35\n",
      "4422/4422 [==============================] - 0s 55us/step - loss: 0.6556 - mean_absolute_error: 0.4295\n",
      "Epoch 35/35\n",
      "4422/4422 [==============================] - 0s 50us/step - loss: 0.8124 - mean_absolute_error: 0.4388\n",
      "Epoch 1/35\n",
      "4422/4422 [==============================] - 1s 133us/step - loss: 50870.0957 - mean_absolute_error: 24.9417\n",
      "Epoch 2/35\n",
      "4422/4422 [==============================] - 0s 49us/step - loss: 29689.7427 - mean_absolute_error: 29.6531\n",
      "Epoch 3/35\n",
      "4422/4422 [==============================] - 0s 49us/step - loss: 63277.2340 - mean_absolute_error: 37.6768\n",
      "Epoch 4/35\n",
      "4422/4422 [==============================] - 0s 46us/step - loss: 22201.3189 - mean_absolute_error: 19.5385\n",
      "Epoch 5/35\n",
      "4422/4422 [==============================] - 0s 45us/step - loss: 16511.0361 - mean_absolute_error: 19.4462\n",
      "Epoch 6/35\n",
      "4422/4422 [==============================] - 0s 46us/step - loss: 14192.9843 - mean_absolute_error: 18.7907\n",
      "Epoch 7/35\n",
      "4422/4422 [==============================] - 0s 49us/step - loss: 9672.1098 - mean_absolute_error: 17.1234\n",
      "Epoch 8/35\n",
      "4422/4422 [==============================] - 0s 65us/step - loss: 8831.2609 - mean_absolute_error: 15.6376\n",
      "Epoch 9/35\n",
      "4422/4422 [==============================] - 0s 52us/step - loss: 16430.4671 - mean_absolute_error: 10.6252\n",
      "Epoch 10/35\n",
      "4422/4422 [==============================] - 0s 51us/step - loss: 4068.8048 - mean_absolute_error: 12.2108\n",
      "Epoch 11/35\n",
      "4422/4422 [==============================] - 0s 49us/step - loss: 1232.5399 - mean_absolute_error: 9.1010\n",
      "Epoch 12/35\n",
      "4422/4422 [==============================] - 0s 63us/step - loss: 2704.5260 - mean_absolute_error: 11.3916\n",
      "Epoch 13/35\n",
      "4422/4422 [==============================] - 0s 63us/step - loss: 2246.4686 - mean_absolute_error: 10.5259\n",
      "Epoch 14/35\n",
      "4422/4422 [==============================] - 0s 63us/step - loss: 2012.2148 - mean_absolute_error: 9.6048\n",
      "Epoch 15/35\n",
      "4422/4422 [==============================] - 0s 51us/step - loss: 1586.6238 - mean_absolute_error: 6.5945\n",
      "Epoch 16/35\n",
      "4422/4422 [==============================] - 0s 69us/step - loss: 1223.5906 - mean_absolute_error: 6.7947\n",
      "Epoch 17/35\n",
      "4422/4422 [==============================] - 0s 53us/step - loss: 1035.8951 - mean_absolute_error: 5.5083\n",
      "Epoch 18/35\n",
      "4422/4422 [==============================] - 0s 61us/step - loss: 879.1696 - mean_absolute_error: 4.9973\n",
      "Epoch 19/35\n",
      "4422/4422 [==============================] - 0s 56us/step - loss: 593.5273 - mean_absolute_error: 4.5187\n",
      "Epoch 20/35\n",
      "4422/4422 [==============================] - 0s 75us/step - loss: 93.8796 - mean_absolute_error: 2.7370\n",
      "Epoch 21/35\n",
      "4422/4422 [==============================] - 0s 53us/step - loss: 45.2031 - mean_absolute_error: 2.3188\n",
      "Epoch 22/35\n",
      "4422/4422 [==============================] - 0s 68us/step - loss: 48.1363 - mean_absolute_error: 2.2267\n",
      "Epoch 23/35\n",
      "4422/4422 [==============================] - 0s 70us/step - loss: 29.8132 - mean_absolute_error: 1.7993\n",
      "Epoch 24/35\n",
      "4422/4422 [==============================] - 0s 67us/step - loss: 43.7661 - mean_absolute_error: 1.4409\n",
      "Epoch 25/35\n",
      "4422/4422 [==============================] - 0s 75us/step - loss: 84.1128 - mean_absolute_error: 1.2495\n",
      "Epoch 26/35\n",
      "4422/4422 [==============================] - 0s 74us/step - loss: 278.8542 - mean_absolute_error: 1.2481\n",
      "Epoch 27/35\n",
      "4422/4422 [==============================] - 0s 67us/step - loss: 1.2215 - mean_absolute_error: 0.5035\n",
      "Epoch 28/35\n",
      "4422/4422 [==============================] - 0s 66us/step - loss: 0.5381 - mean_absolute_error: 0.4465\n",
      "Epoch 29/35\n",
      "4422/4422 [==============================] - 0s 61us/step - loss: 0.7210 - mean_absolute_error: 0.4445\n",
      "Epoch 30/35\n",
      "4422/4422 [==============================] - 0s 55us/step - loss: 2.2535 - mean_absolute_error: 0.4951\n",
      "Epoch 31/35\n",
      "4422/4422 [==============================] - 0s 64us/step - loss: 0.6929 - mean_absolute_error: 0.4536\n",
      "Epoch 32/35\n",
      "4422/4422 [==============================] - 0s 53us/step - loss: 0.5767 - mean_absolute_error: 0.4351\n",
      "Epoch 33/35\n",
      "4422/4422 [==============================] - 0s 65us/step - loss: 0.9560 - mean_absolute_error: 0.4468\n",
      "Epoch 34/35\n",
      "4422/4422 [==============================] - 0s 53us/step - loss: 0.6094 - mean_absolute_error: 0.4319\n",
      "Epoch 35/35\n",
      "4422/4422 [==============================] - 0s 67us/step - loss: 0.3988 - mean_absolute_error: 0.4189\n",
      "Epoch 1/35\n",
      "4422/4422 [==============================] - 1s 170us/step - loss: 46575.1699 - mean_absolute_error: 53.5431\n",
      "Epoch 2/35\n",
      "4422/4422 [==============================] - 0s 66us/step - loss: 54161.4461 - mean_absolute_error: 34.7520\n",
      "Epoch 3/35\n",
      "4422/4422 [==============================] - 0s 53us/step - loss: 33949.9297 - mean_absolute_error: 30.9915\n",
      "Epoch 4/35\n",
      "4422/4422 [==============================] - 0s 53us/step - loss: 24029.2003 - mean_absolute_error: 35.0369\n",
      "Epoch 5/35\n",
      "4422/4422 [==============================] - 0s 63us/step - loss: 18770.1253 - mean_absolute_error: 22.2651\n",
      "Epoch 6/35\n",
      "4422/4422 [==============================] - 0s 83us/step - loss: 14233.7178 - mean_absolute_error: 13.8844\n",
      "Epoch 7/35\n",
      "4422/4422 [==============================] - 0s 60us/step - loss: 11592.7026 - mean_absolute_error: 19.0855\n",
      "Epoch 8/35\n",
      "4422/4422 [==============================] - 0s 94us/step - loss: 8029.6181 - mean_absolute_error: 17.7827\n",
      "Epoch 9/35\n",
      "4422/4422 [==============================] - 0s 64us/step - loss: 15573.4393 - mean_absolute_error: 15.8670\n",
      "Epoch 10/35\n",
      "4422/4422 [==============================] - 0s 57us/step - loss: 8094.7985 - mean_absolute_error: 14.4819\n",
      "Epoch 11/35\n",
      "4422/4422 [==============================] - 0s 53us/step - loss: 4825.9225 - mean_absolute_error: 12.2742\n",
      "Epoch 12/35\n",
      "4422/4422 [==============================] - 0s 58us/step - loss: 3597.7118 - mean_absolute_error: 11.8097\n",
      "Epoch 13/35\n",
      "4422/4422 [==============================] - 0s 51us/step - loss: 2414.9551 - mean_absolute_error: 12.5392\n",
      "Epoch 14/35\n",
      "4422/4422 [==============================] - 0s 52us/step - loss: 2843.1777 - mean_absolute_error: 6.7930\n",
      "Epoch 15/35\n",
      "4422/4422 [==============================] - 0s 54us/step - loss: 1441.2179 - mean_absolute_error: 7.3291\n",
      "Epoch 16/35\n",
      "4422/4422 [==============================] - 0s 54us/step - loss: 643.7977 - mean_absolute_error: 6.7574\n",
      "Epoch 17/35\n",
      "4422/4422 [==============================] - ETA: 0s - loss: 763.5395 - mean_absolute_error: 5.608 - 0s 53us/step - loss: 884.1908 - mean_absolute_error: 5.9864\n",
      "Epoch 18/35\n",
      "4422/4422 [==============================] - 0s 56us/step - loss: 799.2000 - mean_absolute_error: 5.9608\n",
      "Epoch 19/35\n",
      "4422/4422 [==============================] - 0s 53us/step - loss: 521.8841 - mean_absolute_error: 5.9686\n",
      "Epoch 20/35\n",
      "4422/4422 [==============================] - 0s 54us/step - loss: 357.1319 - mean_absolute_error: 4.5670\n",
      "Epoch 21/35\n",
      "4422/4422 [==============================] - 0s 53us/step - loss: 536.1566 - mean_absolute_error: 4.1033\n",
      "Epoch 22/35\n",
      "4422/4422 [==============================] - 0s 54us/step - loss: 555.1506 - mean_absolute_error: 4.7465\n",
      "Epoch 23/35\n",
      "4422/4422 [==============================] - 0s 48us/step - loss: 189.0128 - mean_absolute_error: 3.8774\n",
      "Epoch 24/35\n",
      "4422/4422 [==============================] - 0s 48us/step - loss: 115.7067 - mean_absolute_error: 3.2131\n",
      "Epoch 25/35\n",
      "4422/4422 [==============================] - 0s 60us/step - loss: 242.3868 - mean_absolute_error: 3.1104\n",
      "Epoch 26/35\n",
      "4422/4422 [==============================] - 0s 60us/step - loss: 202.5446 - mean_absolute_error: 3.2899\n",
      "Epoch 27/35\n",
      "4422/4422 [==============================] - 0s 57us/step - loss: 223.9329 - mean_absolute_error: 3.3201\n",
      "Epoch 28/35\n",
      "4422/4422 [==============================] - 0s 57us/step - loss: 38.9954 - mean_absolute_error: 2.1627\n",
      "Epoch 29/35\n",
      "4422/4422 [==============================] - 0s 58us/step - loss: 56.3109 - mean_absolute_error: 2.0031\n",
      "Epoch 30/35\n",
      "4422/4422 [==============================] - 0s 50us/step - loss: 5.4194 - mean_absolute_error: 1.0406\n",
      "Epoch 31/35\n",
      "4422/4422 [==============================] - 0s 48us/step - loss: 0.6125 - mean_absolute_error: 0.5451\n",
      "Epoch 32/35\n",
      "4422/4422 [==============================] - 0s 49us/step - loss: 0.8832 - mean_absolute_error: 0.4759\n",
      "Epoch 33/35\n",
      "4422/4422 [==============================] - 0s 50us/step - loss: 0.5602 - mean_absolute_error: 0.4475\n",
      "Epoch 34/35\n",
      "4422/4422 [==============================] - 0s 49us/step - loss: 0.4953 - mean_absolute_error: 0.4353\n",
      "Epoch 35/35\n",
      "4422/4422 [==============================] - 0s 48us/step - loss: 0.7046 - mean_absolute_error: 0.4430\n",
      "Epoch 1/35\n",
      "4422/4422 [==============================] - 1s 179us/step - loss: 99005.1710 - mean_absolute_error: 54.3924\n",
      "Epoch 2/35\n",
      "4422/4422 [==============================] - 0s 58us/step - loss: 90449.6537 - mean_absolute_error: 36.1360\n",
      "Epoch 3/35\n",
      "4422/4422 [==============================] - 0s 57us/step - loss: 43238.0138 - mean_absolute_error: 43.0938\n",
      "Epoch 4/35\n",
      "4422/4422 [==============================] - 0s 51us/step - loss: 67551.5080 - mean_absolute_error: 44.7399\n",
      "Epoch 5/35\n",
      "4422/4422 [==============================] - 0s 57us/step - loss: 24741.9388 - mean_absolute_error: 33.3097\n",
      "Epoch 6/35\n",
      "4422/4422 [==============================] - 0s 65us/step - loss: 29264.7443 - mean_absolute_error: 19.9799\n",
      "Epoch 7/35\n",
      "4422/4422 [==============================] - 0s 60us/step - loss: 16521.0720 - mean_absolute_error: 19.8237\n",
      "Epoch 8/35\n",
      "4422/4422 [==============================] - 0s 63us/step - loss: 12471.1529 - mean_absolute_error: 19.4975\n",
      "Epoch 9/35\n",
      "4422/4422 [==============================] - 0s 56us/step - loss: 10173.6117 - mean_absolute_error: 17.3967\n",
      "Epoch 10/35\n",
      "4422/4422 [==============================] - 0s 52us/step - loss: 3165.1070 - mean_absolute_error: 12.6971\n",
      "Epoch 11/35\n",
      "4422/4422 [==============================] - 0s 54us/step - loss: 5615.8843 - mean_absolute_error: 12.8590\n",
      "Epoch 12/35\n",
      "4422/4422 [==============================] - 0s 51us/step - loss: 11905.5174 - mean_absolute_error: 15.4273\n",
      "Epoch 13/35\n",
      "4422/4422 [==============================] - 0s 52us/step - loss: 6930.0397 - mean_absolute_error: 14.1657\n",
      "Epoch 14/35\n",
      "4422/4422 [==============================] - 0s 56us/step - loss: 6917.0707 - mean_absolute_error: 14.4748\n",
      "Epoch 15/35\n",
      "4422/4422 [==============================] - 0s 52us/step - loss: 1725.7378 - mean_absolute_error: 9.7264\n",
      "Epoch 16/35\n",
      "4422/4422 [==============================] - 0s 52us/step - loss: 4513.5162 - mean_absolute_error: 14.5891\n",
      "Epoch 17/35\n",
      "4422/4422 [==============================] - 0s 51us/step - loss: 3061.2512 - mean_absolute_error: 11.8311\n",
      "Epoch 18/35\n",
      "4422/4422 [==============================] - 0s 51us/step - loss: 3038.2958 - mean_absolute_error: 10.2838\n",
      "Epoch 19/35\n",
      "4422/4422 [==============================] - 0s 53us/step - loss: 994.8413 - mean_absolute_error: 6.7102\n",
      "Epoch 20/35\n",
      "4422/4422 [==============================] - 0s 51us/step - loss: 1651.2691 - mean_absolute_error: 6.2863 0s - loss: 506.5456 - mean_absolute_error: 5.1\n",
      "Epoch 21/35\n",
      "4422/4422 [==============================] - 0s 51us/step - loss: 623.5354 - mean_absolute_error: 5.3760\n",
      "Epoch 22/35\n",
      "4422/4422 [==============================] - 0s 51us/step - loss: 1215.1570 - mean_absolute_error: 7.1798\n",
      "Epoch 23/35\n",
      "4422/4422 [==============================] - 0s 53us/step - loss: 1724.0366 - mean_absolute_error: 6.0649\n",
      "Epoch 24/35\n",
      "4422/4422 [==============================] - 0s 53us/step - loss: 431.6187 - mean_absolute_error: 4.3195\n",
      "Epoch 25/35\n",
      "4422/4422 [==============================] - 0s 58us/step - loss: 631.9615 - mean_absolute_error: 4.3831\n",
      "Epoch 26/35\n",
      "4422/4422 [==============================] - 0s 49us/step - loss: 295.0502 - mean_absolute_error: 3.7988\n",
      "Epoch 27/35\n",
      "4422/4422 [==============================] - 0s 51us/step - loss: 91.6077 - mean_absolute_error: 2.7239\n",
      "Epoch 28/35\n",
      "4422/4422 [==============================] - 0s 51us/step - loss: 133.3682 - mean_absolute_error: 2.5164\n",
      "Epoch 29/35\n",
      "4422/4422 [==============================] - 0s 51us/step - loss: 112.6013 - mean_absolute_error: 2.0927\n",
      "Epoch 30/35\n",
      "4422/4422 [==============================] - 0s 51us/step - loss: 26.6804 - mean_absolute_error: 1.5425\n",
      "Epoch 31/35\n",
      "4422/4422 [==============================] - 0s 50us/step - loss: 2.5233 - mean_absolute_error: 0.6970\n",
      "Epoch 32/35\n",
      "4422/4422 [==============================] - 0s 53us/step - loss: 0.4156 - mean_absolute_error: 0.4376: 0s - loss: 0.4632 - mean_absolute_error: 0.4\n",
      "Epoch 33/35\n",
      "4422/4422 [==============================] - 0s 54us/step - loss: 0.5198 - mean_absolute_error: 0.4306\n",
      "Epoch 34/35\n",
      "4422/4422 [==============================] - 0s 65us/step - loss: 2.3491 - mean_absolute_error: 0.4492\n",
      "Epoch 35/35\n",
      "4422/4422 [==============================] - 0s 64us/step - loss: 1.3519 - mean_absolute_error: 0.4416\n",
      "Epoch 1/35\n",
      "4422/4422 [==============================] - 1s 167us/step - loss: 230848.1689 - mean_absolute_error: 72.8143\n",
      "Epoch 2/35\n",
      "4422/4422 [==============================] - 0s 53us/step - loss: 111259.4074 - mean_absolute_error: 40.7782s - loss: 2300.7472 - mean_absolute_error: 11.0\n",
      "Epoch 3/35\n",
      "4422/4422 [==============================] - 0s 56us/step - loss: 58843.5484 - mean_absolute_error: 48.7934\n",
      "Epoch 4/35\n",
      "4422/4422 [==============================] - ETA: 0s - loss: 72182.3109 - mean_absolute_error: 28.25 - 0s 52us/step - loss: 76289.2140 - mean_absolute_error: 30.3252\n",
      "Epoch 5/35\n",
      "4422/4422 [==============================] - 0s 55us/step - loss: 86880.6368 - mean_absolute_error: 35.3038\n",
      "Epoch 6/35\n",
      "4422/4422 [==============================] - 0s 55us/step - loss: 26756.2495 - mean_absolute_error: 35.0216\n",
      "Epoch 7/35\n",
      "4422/4422 [==============================] - 0s 58us/step - loss: 57186.6034 - mean_absolute_error: 26.8533\n",
      "Epoch 8/35\n",
      "4422/4422 [==============================] - 0s 64us/step - loss: 73825.4335 - mean_absolute_error: 20.5804\n",
      "Epoch 9/35\n",
      "4422/4422 [==============================] - 0s 65us/step - loss: 46575.8951 - mean_absolute_error: 32.5120\n",
      "Epoch 10/35\n",
      "4422/4422 [==============================] - 0s 61us/step - loss: 24082.1651 - mean_absolute_error: 24.8260\n",
      "Epoch 11/35\n",
      "4422/4422 [==============================] - 0s 56us/step - loss: 21702.4670 - mean_absolute_error: 24.6484\n",
      "Epoch 12/35\n",
      "4422/4422 [==============================] - 0s 57us/step - loss: 10333.2899 - mean_absolute_error: 22.5087\n",
      "Epoch 13/35\n",
      "4422/4422 [==============================] - 0s 55us/step - loss: 6924.6376 - mean_absolute_error: 15.9397\n",
      "Epoch 14/35\n",
      "4422/4422 [==============================] - 0s 55us/step - loss: 16364.6992 - mean_absolute_error: 14.8776\n",
      "Epoch 15/35\n",
      "4422/4422 [==============================] - 0s 56us/step - loss: 11666.8730 - mean_absolute_error: 21.5369\n",
      "Epoch 16/35\n",
      "4422/4422 [==============================] - 0s 53us/step - loss: 28349.4190 - mean_absolute_error: 17.8181\n",
      "Epoch 17/35\n",
      "4422/4422 [==============================] - 0s 57us/step - loss: 24380.9917 - mean_absolute_error: 23.0380\n",
      "Epoch 18/35\n",
      "4422/4422 [==============================] - 0s 51us/step - loss: 7780.8424 - mean_absolute_error: 11.2541\n",
      "Epoch 19/35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4422/4422 [==============================] - 0s 62us/step - loss: 17481.7038 - mean_absolute_error: 18.1030\n",
      "Epoch 20/35\n",
      "4422/4422 [==============================] - 0s 60us/step - loss: 9821.0781 - mean_absolute_error: 17.9875\n",
      "Epoch 21/35\n",
      "4422/4422 [==============================] - 0s 62us/step - loss: 12607.1507 - mean_absolute_error: 23.7575\n",
      "Epoch 22/35\n",
      "4422/4422 [==============================] - 0s 57us/step - loss: 18322.3190 - mean_absolute_error: 15.7226\n",
      "Epoch 23/35\n",
      "4422/4422 [==============================] - 0s 57us/step - loss: 11124.9047 - mean_absolute_error: 18.5282\n",
      "Epoch 24/35\n",
      "4422/4422 [==============================] - 0s 57us/step - loss: 5607.2108 - mean_absolute_error: 11.8142\n",
      "Epoch 25/35\n",
      "4422/4422 [==============================] - 0s 51us/step - loss: 3929.3363 - mean_absolute_error: 9.2287\n",
      "Epoch 26/35\n",
      "4422/4422 [==============================] - 0s 50us/step - loss: 10889.0692 - mean_absolute_error: 16.0156\n",
      "Epoch 27/35\n",
      "4422/4422 [==============================] - 0s 63us/step - loss: 3318.0908 - mean_absolute_error: 8.7173\n",
      "Epoch 28/35\n",
      "4422/4422 [==============================] - 0s 52us/step - loss: 2049.1516 - mean_absolute_error: 9.8033\n",
      "Epoch 29/35\n",
      "4422/4422 [==============================] - 0s 64us/step - loss: 11756.6162 - mean_absolute_error: 16.9424\n",
      "Epoch 30/35\n",
      "4422/4422 [==============================] - 0s 63us/step - loss: 7401.2281 - mean_absolute_error: 15.1534\n",
      "Epoch 31/35\n",
      "4422/4422 [==============================] - 0s 59us/step - loss: 2285.2104 - mean_absolute_error: 8.4732\n",
      "Epoch 32/35\n",
      "4422/4422 [==============================] - 0s 60us/step - loss: 5077.4219 - mean_absolute_error: 10.9566\n",
      "Epoch 33/35\n",
      "4422/4422 [==============================] - 0s 57us/step - loss: 2507.3891 - mean_absolute_error: 7.0315\n",
      "Epoch 34/35\n",
      "4422/4422 [==============================] - 0s 55us/step - loss: 3805.6975 - mean_absolute_error: 10.0391\n",
      "Epoch 35/35\n",
      "4422/4422 [==============================] - 0s 52us/step - loss: 6152.0194 - mean_absolute_error: 8.5447\n",
      "Epoch 1/35\n",
      "4422/4422 [==============================] - 1s 174us/step - loss: 120902.6117 - mean_absolute_error: 44.1390\n",
      "Epoch 2/35\n",
      "4422/4422 [==============================] - 0s 57us/step - loss: 164839.8172 - mean_absolute_error: 40.9248\n",
      "Epoch 3/35\n",
      "4422/4422 [==============================] - 0s 71us/step - loss: 64639.3247 - mean_absolute_error: 41.4793\n",
      "Epoch 4/35\n",
      "4422/4422 [==============================] - 0s 64us/step - loss: 83103.1398 - mean_absolute_error: 59.4881\n",
      "Epoch 5/35\n",
      "4422/4422 [==============================] - 0s 62us/step - loss: 29473.3997 - mean_absolute_error: 37.2034\n",
      "Epoch 6/35\n",
      "4422/4422 [==============================] - 0s 58us/step - loss: 178076.5535 - mean_absolute_error: 22.6579\n",
      "Epoch 7/35\n",
      "4422/4422 [==============================] - 0s 53us/step - loss: 37643.9486 - mean_absolute_error: 28.8015\n",
      "Epoch 8/35\n",
      "4422/4422 [==============================] - 0s 60us/step - loss: 22236.9175 - mean_absolute_error: 20.3729\n",
      "Epoch 9/35\n",
      "4422/4422 [==============================] - 0s 55us/step - loss: 24448.3604 - mean_absolute_error: 24.3128\n",
      "Epoch 10/35\n",
      "4422/4422 [==============================] - 0s 71us/step - loss: 42917.6481 - mean_absolute_error: 30.3825\n",
      "Epoch 11/35\n",
      "4422/4422 [==============================] - 0s 67us/step - loss: 31264.0399 - mean_absolute_error: 30.4427\n",
      "Epoch 12/35\n",
      "4422/4422 [==============================] - 0s 74us/step - loss: 18841.0748 - mean_absolute_error: 25.4842\n",
      "Epoch 13/35\n",
      "4422/4422 [==============================] - 0s 61us/step - loss: 17614.2558 - mean_absolute_error: 24.1899\n",
      "Epoch 14/35\n",
      "4422/4422 [==============================] - 0s 65us/step - loss: 9527.0665 - mean_absolute_error: 17.0736\n",
      "Epoch 15/35\n",
      "4422/4422 [==============================] - 0s 78us/step - loss: 18242.8612 - mean_absolute_error: 14.2211\n",
      "Epoch 16/35\n",
      "4422/4422 [==============================] - 0s 68us/step - loss: 6999.7431 - mean_absolute_error: 13.9886\n",
      "Epoch 17/35\n",
      "4422/4422 [==============================] - 0s 81us/step - loss: 11150.6986 - mean_absolute_error: 14.4093\n",
      "Epoch 18/35\n",
      "4422/4422 [==============================] - 0s 79us/step - loss: 6879.3953 - mean_absolute_error: 13.0445\n",
      "Epoch 19/35\n",
      "4422/4422 [==============================] - 0s 68us/step - loss: 11089.5588 - mean_absolute_error: 17.1658\n",
      "Epoch 20/35\n",
      "4422/4422 [==============================] - 0s 69us/step - loss: 5977.4829 - mean_absolute_error: 11.0381\n",
      "Epoch 21/35\n",
      "4422/4422 [==============================] - 0s 63us/step - loss: 16518.9065 - mean_absolute_error: 10.2491\n",
      "Epoch 22/35\n",
      "4422/4422 [==============================] - 0s 77us/step - loss: 23201.5809 - mean_absolute_error: 11.1275\n",
      "Epoch 23/35\n",
      "4422/4422 [==============================] - 0s 68us/step - loss: 9300.8444 - mean_absolute_error: 15.6707\n",
      "Epoch 24/35\n",
      "4422/4422 [==============================] - 0s 69us/step - loss: 4887.5753 - mean_absolute_error: 13.1471\n",
      "Epoch 25/35\n",
      "4422/4422 [==============================] - 0s 67us/step - loss: 4800.0633 - mean_absolute_error: 13.1261\n",
      "Epoch 26/35\n",
      "4422/4422 [==============================] - 0s 64us/step - loss: 8015.9174 - mean_absolute_error: 18.7254\n",
      "Epoch 27/35\n",
      "4422/4422 [==============================] - 0s 62us/step - loss: 15976.9574 - mean_absolute_error: 17.5922\n",
      "Epoch 28/35\n",
      "4422/4422 [==============================] - 0s 61us/step - loss: 4424.3305 - mean_absolute_error: 10.1796\n",
      "Epoch 29/35\n",
      "4422/4422 [==============================] - 0s 55us/step - loss: 3403.4084 - mean_absolute_error: 12.7678\n",
      "Epoch 30/35\n",
      "4422/4422 [==============================] - 0s 57us/step - loss: 9647.5671 - mean_absolute_error: 19.0147\n",
      "Epoch 31/35\n",
      "4422/4422 [==============================] - 0s 54us/step - loss: 5876.5984 - mean_absolute_error: 12.7267\n",
      "Epoch 32/35\n",
      "4422/4422 [==============================] - 0s 60us/step - loss: 4189.5319 - mean_absolute_error: 9.7943\n",
      "Epoch 33/35\n",
      "4422/4422 [==============================] - 0s 55us/step - loss: 1827.6108 - mean_absolute_error: 8.6324\n",
      "Epoch 34/35\n",
      "4422/4422 [==============================] - 0s 54us/step - loss: 2130.0281 - mean_absolute_error: 9.6235\n",
      "Epoch 35/35\n",
      "4422/4422 [==============================] - 0s 62us/step - loss: 1737.9870 - mean_absolute_error: 8.0331\n",
      "Epoch 1/35\n",
      "4422/4422 [==============================] - 1s 190us/step - loss: 28602.3568 - mean_absolute_error: 34.5166\n",
      "Epoch 2/35\n",
      "4422/4422 [==============================] - 0s 57us/step - loss: 57059.0733 - mean_absolute_error: 21.2063\n",
      "Epoch 3/35\n",
      "4422/4422 [==============================] - 0s 54us/step - loss: 9354.0182 - mean_absolute_error: 19.6745\n",
      "Epoch 4/35\n",
      "4422/4422 [==============================] - 0s 57us/step - loss: 9530.9770 - mean_absolute_error: 20.5678\n",
      "Epoch 5/35\n",
      "4422/4422 [==============================] - 0s 54us/step - loss: 10408.0437 - mean_absolute_error: 19.7047\n",
      "Epoch 6/35\n",
      "4422/4422 [==============================] - 0s 65us/step - loss: 5833.5637 - mean_absolute_error: 16.7414\n",
      "Epoch 7/35\n",
      "4422/4422 [==============================] - 0s 69us/step - loss: 13436.8023 - mean_absolute_error: 14.2081\n",
      "Epoch 8/35\n",
      "4422/4422 [==============================] - 0s 61us/step - loss: 4398.9907 - mean_absolute_error: 10.3579\n",
      "Epoch 9/35\n",
      "4422/4422 [==============================] - 0s 55us/step - loss: 6224.4362 - mean_absolute_error: 13.0130\n",
      "Epoch 10/35\n",
      "4422/4422 [==============================] - 0s 54us/step - loss: 7204.7029 - mean_absolute_error: 10.9360\n",
      "Epoch 11/35\n",
      "4422/4422 [==============================] - 0s 56us/step - loss: 2424.2515 - mean_absolute_error: 12.1007\n",
      "Epoch 12/35\n",
      "4422/4422 [==============================] - 0s 54us/step - loss: 4141.5484 - mean_absolute_error: 10.9037\n",
      "Epoch 13/35\n",
      "4422/4422 [==============================] - 0s 56us/step - loss: 8703.7992 - mean_absolute_error: 19.3512\n",
      "Epoch 14/35\n",
      "4422/4422 [==============================] - 0s 53us/step - loss: 5182.8761 - mean_absolute_error: 14.6710\n",
      "Epoch 15/35\n",
      "4422/4422 [==============================] - 0s 57us/step - loss: 6112.4791 - mean_absolute_error: 15.4405\n",
      "Epoch 16/35\n",
      "4422/4422 [==============================] - 0s 52us/step - loss: 22954.8090 - mean_absolute_error: 10.1654\n",
      "Epoch 17/35\n",
      "4422/4422 [==============================] - 0s 55us/step - loss: 4089.8160 - mean_absolute_error: 10.5077\n",
      "Epoch 18/35\n",
      "4422/4422 [==============================] - 0s 51us/step - loss: 3657.3623 - mean_absolute_error: 12.0817\n",
      "Epoch 19/35\n",
      "4422/4422 [==============================] - 0s 50us/step - loss: 2611.0330 - mean_absolute_error: 9.6282\n",
      "Epoch 20/35\n",
      "4422/4422 [==============================] - 0s 51us/step - loss: 2494.1551 - mean_absolute_error: 9.2897\n",
      "Epoch 21/35\n",
      "4422/4422 [==============================] - 0s 52us/step - loss: 486.2058 - mean_absolute_error: 4.5021\n",
      "Epoch 22/35\n",
      "4422/4422 [==============================] - 0s 51us/step - loss: 1148.2801 - mean_absolute_error: 5.6519\n",
      "Epoch 23/35\n",
      "4422/4422 [==============================] - 0s 51us/step - loss: 901.0014 - mean_absolute_error: 6.1427\n",
      "Epoch 24/35\n",
      "4422/4422 [==============================] - 0s 50us/step - loss: 469.4017 - mean_absolute_error: 4.7691\n",
      "Epoch 25/35\n",
      "4422/4422 [==============================] - 0s 53us/step - loss: 116.2001 - mean_absolute_error: 3.0820\n",
      "Epoch 26/35\n",
      "4422/4422 [==============================] - 0s 51us/step - loss: 298.3751 - mean_absolute_error: 4.0075\n",
      "Epoch 27/35\n",
      "4422/4422 [==============================] - 0s 50us/step - loss: 163.1222 - mean_absolute_error: 3.3464\n",
      "Epoch 28/35\n",
      "4422/4422 [==============================] - 0s 51us/step - loss: 145.6426 - mean_absolute_error: 2.6979\n",
      "Epoch 29/35\n",
      "4422/4422 [==============================] - 0s 50us/step - loss: 126.7599 - mean_absolute_error: 2.6448\n",
      "Epoch 30/35\n",
      "4422/4422 [==============================] - 0s 52us/step - loss: 94.4086 - mean_absolute_error: 2.2966\n",
      "Epoch 31/35\n",
      "4422/4422 [==============================] - 0s 53us/step - loss: 110.7348 - mean_absolute_error: 2.7081\n",
      "Epoch 32/35\n",
      "4422/4422 [==============================] - 0s 60us/step - loss: 25.4874 - mean_absolute_error: 1.7123\n",
      "Epoch 33/35\n",
      "4422/4422 [==============================] - 0s 63us/step - loss: 20.8228 - mean_absolute_error: 1.3180\n",
      "Epoch 34/35\n",
      "4422/4422 [==============================] - 0s 66us/step - loss: 1.1065 - mean_absolute_error: 0.7862\n",
      "Epoch 35/35\n",
      "4422/4422 [==============================] - 0s 63us/step - loss: 0.6193 - mean_absolute_error: 0.4533\n"
     ]
    }
   ],
   "source": [
    "#Define the model\n",
    "seed = 10\n",
    "np.random.seed(seed)\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "for train, test in kfold.split(X, Y):\n",
    "    model = Sequential()\n",
    "    #Add layers in the model\n",
    "    model.add(Dense(128, input_dim=3, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    #Compiler model\n",
    "    model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "    model.fit(X[train], Y[train], epochs=35, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3422680450432655\n",
      "0.42867715520188665\n"
     ]
    }
   ],
   "source": [
    "#Evaluate model on test\n",
    "mse_value, mae_value = model.evaluate(X[test], Y[test], verbose=0)\n",
    "print(mse_value)\n",
    "print(mae_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5694301074350108"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Prediction and check r^2 value\n",
    "y_pred = model.predict(X[test])\n",
    "r2_score(Y[test], y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.2464437 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.037402  ]\n",
      " [ 4.0969057 ]\n",
      " [ 3.9459543 ]\n",
      " [ 4.0969057 ]\n",
      " [ 3.9766402 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0995984 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.18602   ]\n",
      " [ 4.114999  ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.3580866 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 0.43867898]\n",
      " [ 4.0969057 ]\n",
      " [ 0.6712196 ]\n",
      " [ 4.436103  ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 0.09192109]\n",
      " [ 4.0969057 ]\n",
      " [ 4.2175856 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.130432  ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.181238  ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 2.0776255 ]\n",
      " [ 4.157687  ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.7093143 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.1707973 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.110088  ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.278073  ]\n",
      " [ 4.1903944 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0515823 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.006955  ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 3.8692672 ]\n",
      " [ 4.0074983 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 0.24145925]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.1961374 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 3.8959694 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.347011  ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.004936  ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.453184  ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.2307596 ]\n",
      " [ 3.9641876 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.2277956 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0061064 ]\n",
      " [ 4.361868  ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.028894  ]\n",
      " [ 3.9586406 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 3.977602  ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.450963  ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.1096153 ]\n",
      " [ 4.150124  ]\n",
      " [ 3.9477797 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.1582136 ]\n",
      " [-0.12032485]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0547915 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.2075825 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.029684  ]\n",
      " [ 4.0969057 ]\n",
      " [ 3.8943176 ]\n",
      " [ 2.5804546 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0475516 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.1950316 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.192913  ]\n",
      " [ 4.1093225 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 3.8241577 ]\n",
      " [ 4.138485  ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.003625  ]\n",
      " [ 4.144254  ]\n",
      " [ 4.1134987 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.1537194 ]\n",
      " [ 4.0047913 ]\n",
      " [ 4.32198   ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.1289496 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 2.9491425 ]\n",
      " [ 4.1541333 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.033248  ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.1510687 ]\n",
      " [ 4.0969057 ]\n",
      " [ 3.945173  ]\n",
      " [ 4.0969057 ]\n",
      " [ 0.9067509 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0290456 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.161977  ]\n",
      " [ 4.115797  ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.024552  ]\n",
      " [ 3.8493154 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.2162447 ]\n",
      " [ 4.0847044 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.088051  ]\n",
      " [ 2.0537498 ]\n",
      " [ 4.020671  ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.176047  ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0840597 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 3.8141458 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0698323 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.4493904 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.20268   ]\n",
      " [ 4.4747887 ]\n",
      " [ 4.0969057 ]\n",
      " [ 3.766171  ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.113986  ]\n",
      " [ 3.946453  ]\n",
      " [ 5.15572   ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.1287603 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.1170073 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.1440535 ]\n",
      " [ 4.1571755 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 3.897249  ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.169041  ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.1679564 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.1073594 ]\n",
      " [ 3.9986186 ]\n",
      " [ 4.3125668 ]\n",
      " [-0.02605045]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0564632 ]\n",
      " [ 4.08731   ]\n",
      " [ 4.0390797 ]\n",
      " [ 3.9085255 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.2038817 ]\n",
      " [ 4.1106534 ]\n",
      " [ 4.0969057 ]\n",
      " [ 3.7429028 ]\n",
      " [ 4.122758  ]\n",
      " [ 4.096259  ]\n",
      " [ 3.6203017 ]\n",
      " [ 3.9728346 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.17297   ]\n",
      " [ 4.2122326 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.049195  ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.5673366 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.3751698 ]\n",
      " [ 0.24145925]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.2426715 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 1.2989007 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.3382273 ]\n",
      " [ 3.9184313 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.1262197 ]\n",
      " [ 4.0419273 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.129073  ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 3.9935784 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.1655755 ]\n",
      " [ 3.661327  ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.2080436 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 3.9744914 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [-0.04966915]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 3.7886257 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 3.9493585 ]\n",
      " [ 3.861205  ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 3.6504974 ]\n",
      " [ 4.0350533 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.152194  ]\n",
      " [ 4.111492  ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.117349  ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 3.994928  ]\n",
      " [ 4.0969057 ]\n",
      " [ 3.9706075 ]\n",
      " [ 4.0969057 ]\n",
      " [ 1.1540408 ]\n",
      " [ 3.89966   ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.2368174 ]\n",
      " [ 4.000425  ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 0.7340825 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0921526 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.6302366 ]\n",
      " [ 0.47739196]\n",
      " [ 4.0969057 ]\n",
      " [ 4.088326  ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.653087  ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.449988  ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0969057 ]\n",
      " [ 4.0001793 ]\n",
      " [ 0.12269253]\n",
      " [ 4.0969057 ]\n",
      " [ 4.765916  ]\n",
      " [ 4.0969057 ]] [[4.36364]\n",
      " [3.95   ]\n",
      " [4.2    ]\n",
      " ...\n",
      " [4.9    ]\n",
      " [3.9    ]\n",
      " [3.75   ]]\n"
     ]
    }
   ],
   "source": [
    "#Print the predicted and true value.\n",
    "y_pred = model.predict(X[test])\n",
    "print(y_pred, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> This part completes a Neural network for predicting continuous variable. </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Neral Network for predicting multiclass classification problem </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Import all the packages </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, classification_report, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Consider a sample for performing the classification problem </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>is_paid</th>\n",
       "      <th>num_subscribers</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>rating</th>\n",
       "      <th>num_reviews</th>\n",
       "      <th>num_published_lectures</th>\n",
       "      <th>num_published_practice_tests</th>\n",
       "      <th>created</th>\n",
       "      <th>published_time</th>\n",
       "      <th>discount_price__amount</th>\n",
       "      <th>price_detail__amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4520</th>\n",
       "      <td>641236</td>\n",
       "      <td>Basic JavaScript: Build 4 Basic JavaScript Pro...</td>\n",
       "      <td>/course/practical-javascript-javascript-basics/</td>\n",
       "      <td>True</td>\n",
       "      <td>825</td>\n",
       "      <td>4.35000</td>\n",
       "      <td>4.24073</td>\n",
       "      <td>73</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-10-15T09:58:21Z</td>\n",
       "      <td>2016-02-04T03:55:24Z</td>\n",
       "      <td>455.0</td>\n",
       "      <td>4480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18540</th>\n",
       "      <td>3373686</td>\n",
       "      <td>Sales Mastery: Rapid B2B Sales Growth &amp; Epic C...</td>\n",
       "      <td>/course/sales-mastery-rapid-b2b-sales-growth-e...</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>5</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-07-28T18:15:43Z</td>\n",
       "      <td>2020-09-01T23:53:55Z</td>\n",
       "      <td>455.0</td>\n",
       "      <td>1280.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25219</th>\n",
       "      <td>1672148</td>\n",
       "      <td>CNC Lathe programming using G Code</td>\n",
       "      <td>/course/cnc-lathe-programming-using-g-code/</td>\n",
       "      <td>True</td>\n",
       "      <td>1231</td>\n",
       "      <td>4.17949</td>\n",
       "      <td>4.20768</td>\n",
       "      <td>194</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-05-02T07:39:04Z</td>\n",
       "      <td>2018-05-07T17:54:49Z</td>\n",
       "      <td>455.0</td>\n",
       "      <td>2240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27837</th>\n",
       "      <td>2883952</td>\n",
       "      <td>Declarations and Initializations for C Program...</td>\n",
       "      <td>/course/declarations-and-initializations-for-c...</td>\n",
       "      <td>True</td>\n",
       "      <td>5616</td>\n",
       "      <td>3.85000</td>\n",
       "      <td>3.90397</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2020-03-18T20:05:00Z</td>\n",
       "      <td>2020-03-19T17:15:34Z</td>\n",
       "      <td>455.0</td>\n",
       "      <td>1280.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20724</th>\n",
       "      <td>3427566</td>\n",
       "      <td>Financial Management for Entrepreneurs and Fre...</td>\n",
       "      <td>/course/finances-and-budgeting-for-entrepreneu...</td>\n",
       "      <td>True</td>\n",
       "      <td>650</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-08-17T19:14:39Z</td>\n",
       "      <td>2020-08-24T11:26:13Z</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>1600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1612</th>\n",
       "      <td>1051008</td>\n",
       "      <td>MongoDB 3.2: Professional Developer</td>\n",
       "      <td>/course/mongodb-professional-developer/</td>\n",
       "      <td>True</td>\n",
       "      <td>2539</td>\n",
       "      <td>4.56250</td>\n",
       "      <td>4.75055</td>\n",
       "      <td>398</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-12-25T13:51:41Z</td>\n",
       "      <td>2017-01-24T21:59:57Z</td>\n",
       "      <td>455.0</td>\n",
       "      <td>3200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1321</th>\n",
       "      <td>942454</td>\n",
       "      <td>The Complete iOS Development Course. Swift Pro...</td>\n",
       "      <td>/course/learn-full-swift-course-xcode-ios-prog...</td>\n",
       "      <td>True</td>\n",
       "      <td>3025</td>\n",
       "      <td>4.60000</td>\n",
       "      <td>4.64769</td>\n",
       "      <td>517</td>\n",
       "      <td>329</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-08-27T04:18:03Z</td>\n",
       "      <td>2016-09-09T21:37:21Z</td>\n",
       "      <td>468.0</td>\n",
       "      <td>8640.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26451</th>\n",
       "      <td>2263606</td>\n",
       "      <td>Physical Access Hacking Windows Xp, 7, 8, 10, ...</td>\n",
       "      <td>/course/physicalaccesshacking/</td>\n",
       "      <td>True</td>\n",
       "      <td>14096</td>\n",
       "      <td>3.25000</td>\n",
       "      <td>3.02094</td>\n",
       "      <td>76</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-03-10T00:43:45Z</td>\n",
       "      <td>2019-03-21T17:17:26Z</td>\n",
       "      <td>455.0</td>\n",
       "      <td>8640.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2518</th>\n",
       "      <td>1227924</td>\n",
       "      <td>Implementing a Data Warehouse with Microsoft S...</td>\n",
       "      <td>/course/implementing-a-data-warehouse-with-mic...</td>\n",
       "      <td>True</td>\n",
       "      <td>1896</td>\n",
       "      <td>3.97222</td>\n",
       "      <td>3.97406</td>\n",
       "      <td>205</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-05-24T13:24:19Z</td>\n",
       "      <td>2017-05-27T05:56:16Z</td>\n",
       "      <td>455.0</td>\n",
       "      <td>8000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6307</th>\n",
       "      <td>497648</td>\n",
       "      <td>Build a Cordova Chat APP using Strophe and eJa...</td>\n",
       "      <td>/course/create-a-cross-platform-chat-app-using...</td>\n",
       "      <td>True</td>\n",
       "      <td>225</td>\n",
       "      <td>2.65000</td>\n",
       "      <td>2.37468</td>\n",
       "      <td>35</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-05-09T15:46:38Z</td>\n",
       "      <td>2015-08-26T20:04:11Z</td>\n",
       "      <td>455.0</td>\n",
       "      <td>1280.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4913 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                              title  \\\n",
       "4520    641236  Basic JavaScript: Build 4 Basic JavaScript Pro...   \n",
       "18540  3373686  Sales Mastery: Rapid B2B Sales Growth & Epic C...   \n",
       "25219  1672148                 CNC Lathe programming using G Code   \n",
       "27837  2883952  Declarations and Initializations for C Program...   \n",
       "20724  3427566  Financial Management for Entrepreneurs and Fre...   \n",
       "...        ...                                                ...   \n",
       "1612   1051008                MongoDB 3.2: Professional Developer   \n",
       "1321    942454  The Complete iOS Development Course. Swift Pro...   \n",
       "26451  2263606  Physical Access Hacking Windows Xp, 7, 8, 10, ...   \n",
       "2518   1227924  Implementing a Data Warehouse with Microsoft S...   \n",
       "6307    497648  Build a Cordova Chat APP using Strophe and eJa...   \n",
       "\n",
       "                                                     url  is_paid  \\\n",
       "4520     /course/practical-javascript-javascript-basics/     True   \n",
       "18540  /course/sales-mastery-rapid-b2b-sales-growth-e...     True   \n",
       "25219        /course/cnc-lathe-programming-using-g-code/     True   \n",
       "27837  /course/declarations-and-initializations-for-c...     True   \n",
       "20724  /course/finances-and-budgeting-for-entrepreneu...     True   \n",
       "...                                                  ...      ...   \n",
       "1612             /course/mongodb-professional-developer/     True   \n",
       "1321   /course/learn-full-swift-course-xcode-ios-prog...     True   \n",
       "26451                     /course/physicalaccesshacking/     True   \n",
       "2518   /course/implementing-a-data-warehouse-with-mic...     True   \n",
       "6307   /course/create-a-cross-platform-chat-app-using...     True   \n",
       "\n",
       "       num_subscribers  avg_rating   rating  num_reviews  \\\n",
       "4520               825     4.35000  4.24073           73   \n",
       "18540                9     5.00000  5.00000            5   \n",
       "25219             1231     4.17949  4.20768          194   \n",
       "27837             5616     3.85000  3.90397           36   \n",
       "20724              650     5.00000  5.00000            2   \n",
       "...                ...         ...      ...          ...   \n",
       "1612              2539     4.56250  4.75055          398   \n",
       "1321              3025     4.60000  4.64769          517   \n",
       "26451            14096     3.25000  3.02094           76   \n",
       "2518              1896     3.97222  3.97406          205   \n",
       "6307               225     2.65000  2.37468           35   \n",
       "\n",
       "       num_published_lectures  num_published_practice_tests  \\\n",
       "4520                       37                             0   \n",
       "18540                      83                             0   \n",
       "25219                      17                             0   \n",
       "27837                       0                             6   \n",
       "20724                      25                             0   \n",
       "...                       ...                           ...   \n",
       "1612                      132                             0   \n",
       "1321                      329                             0   \n",
       "26451                      68                             0   \n",
       "2518                       70                             0   \n",
       "6307                       27                             0   \n",
       "\n",
       "                    created        published_time  discount_price__amount  \\\n",
       "4520   2015-10-15T09:58:21Z  2016-02-04T03:55:24Z                   455.0   \n",
       "18540  2020-07-28T18:15:43Z  2020-09-01T23:53:55Z                   455.0   \n",
       "25219  2018-05-02T07:39:04Z  2018-05-07T17:54:49Z                   455.0   \n",
       "27837  2020-03-18T20:05:00Z  2020-03-19T17:15:34Z                   455.0   \n",
       "20724  2020-08-17T19:14:39Z  2020-08-24T11:26:13Z                  1600.0   \n",
       "...                     ...                   ...                     ...   \n",
       "1612   2016-12-25T13:51:41Z  2017-01-24T21:59:57Z                   455.0   \n",
       "1321   2016-08-27T04:18:03Z  2016-09-09T21:37:21Z                   468.0   \n",
       "26451  2019-03-10T00:43:45Z  2019-03-21T17:17:26Z                   455.0   \n",
       "2518   2017-05-24T13:24:19Z  2017-05-27T05:56:16Z                   455.0   \n",
       "6307   2015-05-09T15:46:38Z  2015-08-26T20:04:11Z                   455.0   \n",
       "\n",
       "       price_detail__amount  \n",
       "4520                 4480.0  \n",
       "18540                1280.0  \n",
       "25219                2240.0  \n",
       "27837                1280.0  \n",
       "20724                1600.0  \n",
       "...                     ...  \n",
       "1612                 3200.0  \n",
       "1321                 8640.0  \n",
       "26451                8640.0  \n",
       "2518                 8000.0  \n",
       "6307                 1280.0  \n",
       "\n",
       "[4913 rows x 14 columns]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample = df.sample(frac=0.15, axis=0)\n",
    "df_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identify the in[put features and corresponding target vriable.\n",
    "X = df_sample[['rating', 'num_reviews', 'num_published_lectures']].values\n",
    "Y = df_sample[['num_published_practice_tests']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "#Encodeing done as target variable is a categorical one.\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "encoded_Y = encoder.transform(Y)\n",
    "#One hot encoding\n",
    "Y = np_utils.to_categorical(encoded_Y)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3930/3930 [==============================] - 12s 3ms/step - loss: 2.8039 - acc: 0.5265\n",
      "Epoch 2/10\n",
      "3930/3930 [==============================] - 1s 238us/step - loss: 1.6701 - acc: 0.9168\n",
      "Epoch 3/10\n",
      "3930/3930 [==============================] - 1s 223us/step - loss: 1.5036 - acc: 0.9308\n",
      "Epoch 4/10\n",
      "3930/3930 [==============================] - 1s 222us/step - loss: 1.3463 - acc: 0.9305\n",
      "Epoch 5/10\n",
      "3930/3930 [==============================] - 1s 254us/step - loss: 1.2032 - acc: 0.9321\n",
      "Epoch 6/10\n",
      "3930/3930 [==============================] - 1s 231us/step - loss: 1.0755 - acc: 0.9323\n",
      "Epoch 7/10\n",
      "3930/3930 [==============================] - 1s 246us/step - loss: 0.9626 - acc: 0.9328\n",
      "Epoch 8/10\n",
      "3930/3930 [==============================] - 1s 228us/step - loss: 0.8656 - acc: 0.9328\n",
      "Epoch 9/10\n",
      "3930/3930 [==============================] - 1s 240us/step - loss: 0.7774 - acc: 0.9341\n",
      "Epoch 10/10\n",
      "3930/3930 [==============================] - 1s 224us/step - loss: 0.7159 - acc: 0.9321\n",
      "Epoch 1/10\n",
      "3930/3930 [==============================] - 12s 3ms/step - loss: 0.6259 - acc: 0.9025\n",
      "Epoch 2/10\n",
      "3930/3930 [==============================] - 1s 232us/step - loss: 0.5232 - acc: 0.9239\n",
      "Epoch 3/10\n",
      "3930/3930 [==============================] - 1s 230us/step - loss: 0.4966 - acc: 0.9237\n",
      "Epoch 4/10\n",
      "3930/3930 [==============================] - 1s 232us/step - loss: 0.4487 - acc: 0.9249\n",
      "Epoch 5/10\n",
      "3930/3930 [==============================] - 1s 229us/step - loss: 0.4720 - acc: 0.9214\n",
      "Epoch 6/10\n",
      "3930/3930 [==============================] - 1s 232us/step - loss: 0.4918 - acc: 0.9280\n",
      "Epoch 7/10\n",
      "3930/3930 [==============================] - 1s 230us/step - loss: 0.4239 - acc: 0.9300\n",
      "Epoch 8/10\n",
      "3930/3930 [==============================] - 1s 235us/step - loss: 0.4358 - acc: 0.9092\n",
      "Epoch 9/10\n",
      "3930/3930 [==============================] - 1s 232us/step - loss: 0.3862 - acc: 0.9104\n",
      "Epoch 10/10\n",
      "3930/3930 [==============================] - 1s 232us/step - loss: 0.3571 - acc: 0.9282\n",
      "Epoch 1/10\n",
      "3930/3930 [==============================] - 12s 3ms/step - loss: 2.6275 - acc: 0.4298\n",
      "Epoch 2/10\n",
      "3930/3930 [==============================] - 1s 231us/step - loss: 0.5730 - acc: 0.9107\n",
      "Epoch 3/10\n",
      "3930/3930 [==============================] - 1s 235us/step - loss: 0.5125 - acc: 0.9089\n",
      "Epoch 4/10\n",
      "3930/3930 [==============================] - 1s 231us/step - loss: 0.5097 - acc: 0.9109\n",
      "Epoch 5/10\n",
      "3930/3930 [==============================] - 1s 232us/step - loss: 0.4488 - acc: 0.9102\n",
      "Epoch 6/10\n",
      "3930/3930 [==============================] - 1s 230us/step - loss: 0.4226 - acc: 0.9107\n",
      "Epoch 7/10\n",
      "3930/3930 [==============================] - 1s 231us/step - loss: 0.4076 - acc: 0.9104\n",
      "Epoch 8/10\n",
      "3930/3930 [==============================] - 1s 230us/step - loss: 0.4260 - acc: 0.9109\n",
      "Epoch 9/10\n",
      "3930/3930 [==============================] - 1s 229us/step - loss: 0.3701 - acc: 0.9109\n",
      "Epoch 10/10\n",
      "3930/3930 [==============================] - 1s 232us/step - loss: 0.4481 - acc: 0.9109\n",
      "Epoch 1/10\n",
      "3931/3931 [==============================] - 12s 3ms/step - loss: 4.5673 - acc: 0.5345\n",
      "Epoch 2/10\n",
      "3931/3931 [==============================] - 1s 228us/step - loss: 0.6780 - acc: 0.9089\n",
      "Epoch 3/10\n",
      "3931/3931 [==============================] - 1s 228us/step - loss: 0.5101 - acc: 0.9222\n",
      "Epoch 4/10\n",
      "3931/3931 [==============================] - 1s 229us/step - loss: 0.4894 - acc: 0.9262\n",
      "Epoch 5/10\n",
      "3931/3931 [==============================] - 1s 229us/step - loss: 0.4516 - acc: 0.9270\n",
      "Epoch 6/10\n",
      "3931/3931 [==============================] - 1s 232us/step - loss: 0.4235 - acc: 0.9260\n",
      "Epoch 7/10\n",
      "3931/3931 [==============================] - 1s 231us/step - loss: 0.4098 - acc: 0.9290\n",
      "Epoch 8/10\n",
      "3931/3931 [==============================] - 1s 240us/step - loss: 0.4099 - acc: 0.9270\n",
      "Epoch 9/10\n",
      "3931/3931 [==============================] - 1s 231us/step - loss: 0.3738 - acc: 0.9275\n",
      "Epoch 10/10\n",
      "3931/3931 [==============================] - 1s 253us/step - loss: 0.3912 - acc: 0.9278\n",
      "Epoch 1/10\n",
      "3931/3931 [==============================] - 13s 3ms/step - loss: 1.3812 - acc: 0.6161\n",
      "Epoch 2/10\n",
      "3931/3931 [==============================] - 1s 230us/step - loss: 0.5540 - acc: 0.9099\n",
      "Epoch 3/10\n",
      "3931/3931 [==============================] - 1s 231us/step - loss: 0.4922 - acc: 0.9099\n",
      "Epoch 4/10\n",
      "3931/3931 [==============================] - 1s 231us/step - loss: 0.4789 - acc: 0.9099\n",
      "Epoch 5/10\n",
      "3931/3931 [==============================] - 1s 232us/step - loss: 0.4765 - acc: 0.9099\n",
      "Epoch 6/10\n",
      "3931/3931 [==============================] - 1s 230us/step - loss: 0.4648 - acc: 0.9099\n",
      "Epoch 7/10\n",
      "3931/3931 [==============================] - 1s 237us/step - loss: 0.4539 - acc: 0.9099\n",
      "Epoch 8/10\n",
      "3931/3931 [==============================] - 1s 236us/step - loss: 0.4474 - acc: 0.9099\n",
      "Epoch 9/10\n",
      "3931/3931 [==============================] - 1s 251us/step - loss: 0.4345 - acc: 0.9099\n",
      "Epoch 10/10\n",
      "3931/3931 [==============================] - 1s 244us/step - loss: 0.4250 - acc: 0.9099\n"
     ]
    }
   ],
   "source": [
    "#Define the classification model\n",
    "seed = 20\n",
    "np.random.seed(seed)\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "for train, test in kfold.split(X, Y):\n",
    "    model = Sequential()\n",
    "    #Add layers in the model\n",
    "    model.add(Dense(24, input_dim=3, activation='relu'))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(7, activation='softmax'))\n",
    "    #Compiler model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(X[train], Y[train], epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.4820562945849541\n",
      "Accuracy:  0.9134419548292996\n"
     ]
    }
   ],
   "source": [
    "#Evaluate model on test\n",
    "loss, accuracy = model.evaluate(X[test], Y[test], verbose=0)\n",
    "print(\"Loss: \", loss)\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] [0 6 1 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 2 2 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 3 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 2\n",
      " 0 0 2 0 0 0 0 0 0 0 0 0 4 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 2 0 0 0 0 0 0 0 0 0 5 3 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 4 0 2 0 0 0 0 0 0 0 0 2 0 0 0 6 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 3 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0\n",
      " 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 2 1 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 6 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 5 0 4 0 0 0 0 5 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 0 0 0 0 2 0 0 0 0 0 2\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 6 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 6 0 0 3 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 4 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 5 0 0 0 0 0 0 5 2 0 0 0 0 0 0 0\n",
      " 2 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 2 0 3 0 0 0 0 0 0 0 0\n",
      " 0 0 6 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 6 0 0 0 0 0 2 0 0 0 0 0 2 0 0 0\n",
      " 0 2 0 0 0 0 0 0 0 0 0 6 0 0 0 5 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 5 0 1 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 4 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "#Predict and compare with true values\n",
    "y_pred = model.predict(X[test])\n",
    "Y_prediction = y_pred.argmax(1)\n",
    "Y_test = Y[test].argmax(1)\n",
    "print(Y_prediction, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[897   0   0   0   0   0   0]\n",
      " [ 18   0   0   0   0   0   0]\n",
      " [ 26   0   0   0   0   0   0]\n",
      " [  9   0   0   0   0   0   0]\n",
      " [ 11   0   0   0   0   0   0]\n",
      " [  9   0   0   0   0   0   0]\n",
      " [ 12   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "#Confusion matrix and other metrics:\n",
    "print(confusion_matrix(Y_test, Y_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9134419551934827\n",
      "F1 score: 0.8721207384870185\n",
      "Recall: 0.9134419551934827\n",
      "Precision: 0.8343762055076924\n",
      "\n",
      " clasification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95       897\n",
      "           1       0.00      0.00      0.00        18\n",
      "           2       0.00      0.00      0.00        26\n",
      "           3       0.00      0.00      0.00         9\n",
      "           4       0.00      0.00      0.00        11\n",
      "           5       0.00      0.00      0.00         9\n",
      "           6       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.91       982\n",
      "   macro avg       0.13      0.14      0.14       982\n",
      "weighted avg       0.83      0.91      0.87       982\n",
      "\n",
      "\n",
      " confussion matrix:\n",
      " [[897   0   0   0   0   0   0]\n",
      " [ 18   0   0   0   0   0   0]\n",
      " [ 26   0   0   0   0   0   0]\n",
      " [  9   0   0   0   0   0   0]\n",
      " [ 11   0   0   0   0   0   0]\n",
      " [  9   0   0   0   0   0   0]\n",
      " [ 12   0   0   0   0   0   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "e:\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#All the metrics and evaluation results.\n",
    "print('Accuracy:', accuracy_score(Y_test, Y_prediction))\n",
    "print('F1 score:', f1_score(Y_test, Y_prediction, average='weighted'))\n",
    "print('Recall:', recall_score(Y_test, Y_prediction, average='weighted'))\n",
    "print('Precision:', precision_score(Y_test, Y_prediction, average='weighted'))\n",
    "print('\\n clasification report:\\n', classification_report(Y_test, Y_prediction))\n",
    "print('\\n confussion matrix:\\n',confusion_matrix(Y_test, Y_prediction))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
